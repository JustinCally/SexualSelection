---
title: 'Sexual selection improves population fitness: a meta-analysis'
author: "Justin G. Cally^1^, Devi Stuart-Fox^1^ and Luke Holman^1^ <br></br> <br></br> ^1^The University of Melbourne"
subtitle: Supplementary Material
bibliography: bibliography_meta_analysis.bib
output:
  html_document:
    toc: true # table of content true
    toc_float: true # make 
    depth: 3  # upto three depths of headings (specified by #, ## and ###)
    number_sections: false  ## if you want number sections at each table header
    theme: yeti # lovely fonts and colours
    code_folding: hide # awesome buttons to show/hide the code
  pdf_document: default
---

```{r, warning=FALSE, message=FALSE, results='hide'}
library(pander)
library(tidyr)
library(compute.es)
library(metafor)
library(plyr)
library(dplyr)
library(lme4)
library(car)
library(forestplot)
library(ggplot2)
library(ggthemes)
library(kableExtra)
library(ggrepel)
library(reshape2)
library(RColorBrewer)
library(ggridges)
library(rstan) #Note that installation requires some effort: dependency for brms
library(brms) 
library(backports) #seems to be a dependency
library(bayesplot)
#devtools::install_github("mvuorre/brmstools")
library(brmstools)
library(metaAidR)
source("I2_function.R") #Adapted function for obtaining I2 with CIs
source("Vdodge_function.R") # nice function for ggplot
source("Tidy_functions_for_brms.R") #Tidy functions for making model tables for brms
```

```{r echo=FALSE, results='hide', warning=FALSE}
library(knitr) # set up cacheing to save time when re-building the html document
```
`r opts_chunk$set(cache=TRUE)`



## Supplementary Methods


Our aim was to investigate the effects of sexual selection on population fitness by conducting a meta-analysis on studies that measured fitness related outcomes after experimentally evolving a population under varying levels of opportunity for sexual selection. Here we describe the process of the literature search, data extraction, effect size calculation, formulation of multilevel models and assessing publication bias. We used the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) as a guide during this meta-analysis. The repository used to formulate this document can be found here: https://github.com/JustinCally/SexualSelection 

### Literature Search

**The literature search was conducted under the following conditions:**

1. We searched ISI Web of Science and Scopus on 9th June 2017. The two search engines produded a somewhat different set of papers (**see PRISMA Figure in manuscript**).

2. Studies were restricted to those from peer-reviewed and in the English language.

3. We devised a search strategy that sought to find studies which manipulated the presence or strength of sexual selection using experimental evolution, and then measured some proxy of population fitness. As such the search terms were as follows: 

<br></br>

**_ISI Web of Science_**

We used the following search on ISI Web of Science:

Topic (TS) = “Sexual Selection” OR Promisc* OR Monogam* OR Polygam* OR Polyandr* OR Polygyn* OR “Mate choice”

AND

Topic (TS) = Fitness OR “Population Fitness” OR Deleterious OR “Male Strength” OR Fecund* OR Viability OR Productiv* OR “Reproductive Success” OR “Reproductive Rate” OR Surviv* OR | “Development Rate” OR Extinct* OR “Competitive Success” OR Mortality OR Mass OR “Body Size” OR “Wing Size” OR Emergence OR Mating Rate OR “Mating Propensity” OR Adapt* OR “Novel | Environment” OR “Sexual Conflict” OR “Sexual Antagonis*”

AND

Topic (TS) = Generations OR “Experimental evolution” OR “mutation load”

AND

Research Area (SU) = “Evolutionary Biology”

<br></br>

**_Scopus_**

We used the following search on Scopus:

TITLE-ABS-KEY = “Sexual Selection” OR Promisc* OR Monogam* OR Polygam* OR Polyandr* OR Polygyn* OR “Mate choice”

AND

TITLE-ABS-KEY = Fitness OR “Population Fitness” OR Deleterious OR “Male Strength” OR Fecund* OR Viability OR Productiv* OR “Reproductive Success” OR “Reproductive Rate” OR Surviv* | OR “Development Rate” OR Extinct* OR “Competitive Success” OR Mortality OR Mass OR “Body Size” OR “Wing Size” OR Emergence OR Mating Rate OR “Mating Propensity” OR Adapt* OR | “Novel Environment” OR “Sexual Conflict” OR “Sexual Antagonis*”

AND

TITLE-ABS-KEY = Generations OR “Experimental evolution” OR “mutation load”

### Additions to the Literature Search

In addition to studies found from the literature search we also included three relevant studies that we found, which were not picked up in the subsequent formal searches [@Partridge_1980; @Price_2010; @Savic_2013] **see PRISMA Figure in manuscript**. 

###Inclusion/Exclusion criteria

After removing duplicates papers recovered from both _Web of Science_ and _Scopus_, we read the titles and abstracts of the remaining 1015 papers, and removed papers that were not relevant (typically because they were not an empirical study using experimental evolution). This left 130 papers, for which we read the full text and applied the following selection criteria: 

  + **(1: Study Design)** The study was an experimental evolution study lasting >1 generation
  + **(2: Population)** a) The study was conducted using an animal species that was b) dioecious
  + **(3: Intervention and Control)** The study experimentally manipulated the strength of sexual selection for at least one generation (e.g. via enforced monogamy or an altered sex ratio)
  + **(4: Outcomes)** The study measured a trait that we judged to be a potential correlate of population fitness. 
  
This latter criterion is likely to be contentious, because there is rarely enough data justify the assumption that a particular trait is (or is not) correlated with population fitness. We therefore relied on our best judgement when deciding which studies to exclude (see **Table S1**). The inclusion/exlusion critera as applied to each study are detailed in **Table S2**.

**Table S1:** We classed each of the twenty fitness related outcomes into three broad groups of direct, indirect and ambiguous based on the established link with population fitness, the directionality of the measure. Here we detailed how these outcomes were measured in the studies of this meta-analysis. In the accompanying box we provide a legend to the references cited in the table.

 <br/><br/>
```{r, warning=FALSE}
outcome.descriptions <- read.csv('data/outcome.descriptions.csv', 
                                 fileEncoding="UTF-8")
kable(outcome.descriptions, "html") %>%
  kable_styling() %>%
  scroll_box(width = "100%", height = "500px")
```
  <br/><br/> 
<input type=button class=hideshow></input>
```{r, warning=FALSE}
outcome.references <- read.csv('data/references.tableS1.csv', 
                                 fileEncoding="UTF-8")
kable(outcome.references, "html") %>%
  kable_styling() %>%
  scroll_box(width = "100%", height = "250px")
```
  <br/><br/> 

**Table S2:** An eligibility criteria was based on four features a study needed to include (discussed above), to be eligable for inclusion in the meta-analysis the study needed to satisfy all criteria. Here we applied a step-wise process to the studies that had their full-text read and excluded them when they first failed to meet the criteria. Additional notes documenting reasons behind exclusion were also taken.
 <br/><br/> 
<input type=button class=hideshow></input>
```{r}
Eligibility.criteria <- read.csv('data/Eligibility Workbook(22.02).csv', 
                                 fileEncoding="UTF-8")
kable(Eligibility.criteria, "html") %>%
  kable_styling() %>%
  scroll_box(width = "100%", height = "500px")
```



### Data Extraction and Effect Size Calculation

The rules utilised during the data extraction and effect size calculation were as follows:

1. Arithmatic means, standard deviations/errors and sample sizes were extracted from a paper, supplementary material or a linked data repository (e.g. Data Dryad). This was possible when means and SD were reported in text or in a table. We would preferentially extract data for each experimental evolution line/replicat/family if possible and only extract data for the final reported generation (which was noted down).

2. If we could not find the means and SD in text format we used web-plot digitizer (v.3.12) to extract data from graphs. 

3. If means were not reported then we extracted a summary statistic or proportion value, which we could later convert to Hedges g' using the _compute.es_ package [@compute_es]. Summary statistics included _F_, _z_, _t_ and _chi^2^_. These conversions still required providing sample sizes for each treatment so these needed to be extractable from the study. Some summary statistics were obtained from generalized linear model summary tabels, others from straight forward ANOVAs and then some from more complex analysis such as proportional hazards statistical tests. 

4. We also collected various covariates for some of the studies (**Table S3**), which are discussed later.

______________

## The Effect Size Dataset

### Table of Effect Sizes

**Table S3:** Table of effect sizes included in our meta-analysis. See the text following the table for an explanation of each column.
 <br/><br/> 
<input type=button class=hideshow></input>
```{r}
# Load the data and clean up the variable formats
prelim.data <- read.csv('data/Preliminary data frame 22.2.18.csv')
prelim.data$Study.ID <- prelim.data$Study.ID %>% factor()
prelim.data$Group.ID <- prelim.data$Group.ID %>% factor()
prelim.data$Environment <- prelim.data$Environment %>% relevel(ref="Unstressed")
prelim.data$Sex <- prelim.data$Sex %>% relevel(ref="B")

#Outcome.Class.2 is using the categories that were decided by survey. I am keeping both just to check them against each other (how much of a difference it makes)
prelim.data$Outcome.Class <- prelim.data$Outcome.Class %>% relevel(ref="Indirect")
prelim.data$Enforced.Monogamy <- prelim.data$Enforced.Monogamy %>% relevel(ref="NO")
prelim.data$Pre.cop <- prelim.data$Pre.cop %>% factor() %>% relevel(ref="0")
prelim.data$Post.cop <- prelim.data$Post.cop %>% factor() %>% relevel(ref="0")
prelim.data$Blinding <- prelim.data$Blinding %>% factor()

kable(prelim.data, "html") %>%
  kable_styling() %>%
  scroll_box(width = "100%", height = "500px")
```
<br></br>

**Study ID**: An ID given to the published paper the effect size is sourced from (n=65).

**Group ID**: An ID given to the research group that may have published several papers on the same species usuing the same or very similar experimental setup. [Was not use in analysis]

**Species**: The species used in the experimental evolution procedure (n = 15).

**Taxon**: The taxon to which the species belongs. One of the following: Beetle, fly, mouse, nematode, guppy, mite and cricket (taxa were selected arbitrarily based on the available data). 

**SS Strength, Ratios and SS Density's (Column 7-9)**: Various ratios of the number of males to females and the total number of individuals kept together in an experiment [Was not used in any analysis]

**Post cop and Pre cop**: Whether a study allowed Pre/Post-copulatory sexual selection (1) or not (0).

**Blinding**: A binary classification, describing whether blind protocols were used during the experiment. Papers were assumed to be not blind unless declared otherwise.

**Generations**: The number of generations that the species was subject to differing levels of sexual selection, ranging from 1 to 162. 

**Enforced Monogamy**: Whether the study had the low sexual selection treatment as enforced monogamy (YES) or not (NO). Not all studies compared enforced monogamy and SS+ treatments. Some used FB vs MB, where FB is the SS (low intensity). 

**n**: Pooled sample size of the paired treatments.

**Outcome**: The fitness related outcome that was measured, e.g. fecundity, survival, or mating success (see Table S1 for all 20 categories). We applied our own classifications rather than relying on those provided by the authors, because different papers sometimes used different names for the same trait. 

**Outcome Class**: To help guide analysis the outcomes were classed into three categories; ambiguous, indirect and direct (see Table S1).

**Sex**: A moderator variable with three levels, describing whether the effect size in question comes from a measurement of males (M), females (F), or individuals of both sexes (B).

**Ambiguous**: Is the fitness outcome ambiguous (YES) or not ambigous (NO). Ambiguous outcomes may be those that may not necessarily be directional, that is to say they may be a life history trait. 

**Environment**: In the methods of the papers included in this study it was usually stated whether additional modifications to the experimental lines were made. Briefly, this was usually a modification that made conditions more stressful such as using a novel food source or elevated mutation load, the effect sizes from these experimental lines are labelled as 'Stressed'. If it was clearly stated that there was no such modification it is labelled 'Unstressed'. However, sometimes the paper was ambiguous in what lines had added stress or the results from stressed and unstressed lines were pooled together, in this case we label it as 'Not Stated'.

**g**: Hedge's g calculated using the compute.es package.

**var.g**: The within study variance associated with the effect size, g.

**Positive Fitness**: Whether the measurment used in the study is beneficial for fitness (1) or not (0). Note that g has already been multiplied by this column. We inverted all of the effect sizes pertaining to fitness outcomes that are expected to be negatively related to fitness by multiplying the effect size by -1.

**mean/sd/n.low/high**: The means, standard deviation and sample size for the low or high sexual selection treatments, used to calculate lnCVR (meta-analysis of variance). Rows without these values (NA) had hedges g' derived from summary statistics (F, z, chi-square etc.).

**JIF**: Journal Impact factor at year of publication. Several impact factors were unable to be determined/found and are NA.We obtained the journal impact factor for each effect size at the time of publication using InCites Journal Citation Reports.

_________

### Tables of Sample Sizes

Here we present the number of effect sizes, publications, blind experiments, effect sizes in stresful conditions, male, female and both measures and different species used. 

**Table S4:** Table of effect sizes included in our meta-analysis. See the text following the data table for an explanation of each column.
 <br/><br/> 
```{r message=FALSE, warning=FALSE}
n.blind.ones <- (sum(prelim.data$Blind == "Blind"))
prelim.data %>% 
  summarise(
    Effect_sizes_.Totalq = n(), 
    Publications = prelim.data$Study.ID %>% unique() %>% length(),
    Blind_experiments = n.blind.ones,
    Effect_sizes_.Enforced_monogamyq = (sum(prelim.data$Enforced.Monogamy == "YES")),
    Effect_sizes_.Ambiguousq = (sum(prelim.data$Outcome.Class == "Ambiguous")),
    Effect_sizes_.Indirectq = (sum(prelim.data$Outcome.Class == "Indirect")),
    Effect_sizes_.Directq = (sum(prelim.data$Outcome.Class == "Direct")),
    Effect_sizes_.Stressfulq = (sum(prelim.data$Environment == "Stressed")),
    Effect_sizes_.Benignq = (sum(prelim.data$Environment == "Unstressed")),         
    Effect_sizes_.Maleq = (sum(prelim.data$Sex == "M")),
    Effect_sizes_.Femaleq = (sum(prelim.data$Sex == "F")),
    Effect_sizes_.Both_sexesq = (sum(prelim.data$Sex == "B")),
    Different_species =  prelim.data$Species %>% unique() %>% length(),
    Effect_sizes_.Beetleq = sum(Taxon == "Beetle"),
    Effect_sizes_.Flyq = sum(Taxon == "Fly"),
    Effect_sizes_.Mouseq = sum(Taxon == "Mouse"),
    Effect_sizes_.Nematodeq = sum(Taxon == "Nematode"),
    Effect_sizes_.Miteq = sum(Taxon == "Mite"),
    Effect_sizes_.Cricketq = sum(Taxon == "Cricket"),
    Effect_sizes_.Guppyq = sum(Taxon == "Guppy")) %>% melt() %>%
  mutate(variable = gsub("_", " ", variable),
         variable = gsub("[.]", "(", variable),
         variable = gsub("q", ")", variable)) %>% 
  rename_("n" = "value", " " = "variable") %>% 
  pander(split.cell = 40, split.table = Inf)
```
 <br/><br/> 
**Table S5:** Table of fitness outcomes included in our meta-analysis by sex.
 <br/><br/> 
```{r}
Outcome_and_sex <- as.data.frame.matrix(table(prelim.data$Outcome, prelim.data$Sex))
colnames(Outcome_and_sex) <- cbind("Both", "Female", "Male")

Outcome_and_sex %>% pander(split.cell = 40, split.table = Inf)
```

____________

### Forest Plot


```{r, fig.height=18, fig.width=12}
# Create new factor to order factors in a way where Ambig, Indirect and Direct are Grouped
prelim.data$Outcome_f = factor(prelim.data$Outcome, levels = c('Behavioural Plasticity', 'Body Size', 'Development Rate', 'Early Fecundity', 'Immunity', 'Mating Duration', 'Pesticide Resistance', 'Mutant Frequency', 'Body Condition', 'Fitness Senescence', 'Lifespan', 'Male Attractiveness', 'Mating Frequency', 'Mating Latency', 'Mating Success', 'Strength', 'Ejaculate Quality and Production', 'Extinction Rate', 'Offspring Viability', 'Reproductive Success'))

# define upper and lower bounds
prelim.data$lowerci <- prelim.data$g - 1.96*(sqrt(prelim.data$var.g))
prelim.data$upperci <- prelim.data$g + 1.96*(sqrt(prelim.data$var.g))

library(ggthemes)
#Generate a plot
p.meta <- prelim.data %>% 
  mutate(Sex = replace(as.character(Sex), Sex == "B", "Both"),
         Sex = replace(Sex, Sex == "M", "Male"),
         Sex = replace(Sex, Sex == "F", "Female"),
         Outcome.Class = factor(Outcome.Class, levels = c("Ambiguous", "Indirect", "Direct"))) %>%

  
  ggplot(aes(y=reorder(AuthorYear, -g), x = g)) +
  
  scale_color_manual(values = c("Ambiguous" = "#a50f15", "Indirect" = "#fe9929", "Direct" = "#4daf4a"), 
                    name = "Relationship\nto fitness")+
  
  scale_shape_manual(values=c(21,22,24))+
  
    
  scale_fill_manual(values = c("Ambiguous" = "#a50f15", "Indirect" = "#fe9929", "Direct" = "#4daf4a"), 
                    name = "Relationship\nto fitness")+
  
  
  geom_errorbarh(aes(xmin = lowerci, 
                     xmax = upperci,
                     color = Outcome.Class), height = 0.1, show.legend = FALSE) +
  

  geom_point(aes(shape = Sex,
                 fill = Outcome.Class), 
             size = 1.75, 
             color = "grey20") +
  
  scale_x_continuous(limits=c(-3.35, 12), 
                     breaks = c(-3, -2, -1, 0, 1, 2, 3), 
                     name='                              Standardized Mean Difference (g) \n[positive values indicate sexual selection improves fitness components]') +

  ylab('Reference') + 
  
  geom_vline(xintercept=0, 
             color='black', 
             linetype='dashed')+
  
  facet_grid(Outcome_f~.,
             labeller = label_wrap_gen(width=23),
             scales= 'free', 
             space='free')+
  
  guides(fill = guide_legend(override.aes = list(shape = 21, colour = "grey20", size = 6)),
         shape = guide_legend(override.aes = list(size = 4.5)))+
  
  #Add theme specifying text size, margins, lines etc.
  theme_bw()+
  
  theme(strip.text.y = element_text(angle = 0, size = 8, margin = margin(t=15, r=15, b=15, l=15)), 
        strip.background = element_rect(colour = NULL,
                                        linetype = "blank",
                                        fill = "gray90"),
        text = element_text(size=11),
        panel.spacing = unit(0.5, "lines"),
        panel.border= element_blank(),
        axis.line=element_line(), 
        panel.grid.major.x = element_line(linetype = "solid", colour = "gray95"),
        panel.grid.major.y = element_line(linetype = "solid", color = "gray95"),
        panel.grid.minor.y = element_blank(),
        panel.grid.minor.x = element_blank(), 
        legend.text = element_text(size=12), 
        legend.title=element_text(size=12, 
                                  face = "bold"),
        axis.title.x = element_text(hjust = 0, size = 12))


### We can save the file in several vector graphics forms

#ggsave(plot = p.meta, filename = "figures/Big_forest_plot.eps", height = 18, width = 12)

# svg("figures/Big_forest_plot.svg", width=12, height=18)
# p.meta
# dev.off()
# 
# pdf("figures/Big_forest_plot.pdf", width=12, height=18)
# p.meta
# dev.off()

p.meta
```
<br></br>
**Figure S1:** Forest plot of raw effect sizes and their 95% confidence intervals, grouped according to measured fitness components and the sex of the individuals whose fitness trait was measured (male, female, or both sexes mixed together). Rows with multiple data points denote studies that provided multiple effect sizes. Positive values indicate fitness benefits of sexual selection. 

______________

## Meta-Analysis

###Overall effect of sexual selection on fitness 

We can obtain an overall weghted grand mean and confidence intervals with a simple intercept only for both Bayesian and REML models. Notably, in both models the estimates are approximately the same, with Bayesian estimates being marginally wider. The priors for ``brms`` are set from a weakly non-informative student t-distribution: ``student_t(3, 0, 10)``. Notew that narrowing the prior (e.g. standard normal distribution: ``normal(0,1)``) has negligible effects on the model results. 

```{r, warning = FALSE, results='hide', message=FALSE, error = FALSE, eval=FALSE}
grand.mean.bayes <- brm(g | se(SE)  ~ 1 #Note that running se(SE, sigma = TRUE) gives different result due to a difference in priors
                + (1|Study.ID)
                + (1|Outcome)
                + (1|Taxon), 
                family = "gaussian", 
                seed = 1,
                cores = 4, chains = 4, iter = 4000, #Run 4 chains in parallel for 4000 iterations (2000 are burn in)
                control = list(adapt_delta = 0.9999, max_treedepth = 15),
                data = prelim.data %>% mutate(SE = sqrt(var.g)))

saveRDS(grand.mean.bayes, "data/grand.mean.bayes.rds") #Save to avoid re-running during knit
```

```{r}
#Inspect this for details of random/group level effects
grand.mean.bayes <- readRDS("data/grand.mean.bayes.rds")

#Run REML model 
forest.model <- rma.mv(g, var.g,
                       mods = ~ 1,
                       random = list(~ 1 | Study.ID,
                                      ~ 1 | Outcome,
                                      ~ 1 | Taxon),
                       method = "REML",
                       data = prelim.data)

#Manually imput bayesian results: brms model object difficult to extract from
mean = c(forest.model$b, 0.23) #Values for Bayesian can be obtained from grand.mean.bayes model object
LCI = c(forest.model$ci.lb, -0.06)
UCI = c(forest.model$ci.ub, 0.51)
Stat = c(forest.model$pval, 18.09) #BF can be obtained with: hypothesis(grand.mean.bayes, "Intercept > 0")
grand.means.df <- data.frame(rbind(mean, LCI, UCI, Stat))
colnames(grand.means.df) = c("REML", "Bayesian")
grand.means.df %>% pander(digits = 2)
```

____________________

###Effect of Sexual Selection for different fitness components

Instead of running individual models for each fitness component we can run a model with the fitness components as predictors. In this case we maintain all of our fitness components and include study.id as a group level effect (to account for within study correlations in effect size). Using the ``brms`` package we can run a Bayesian model and generate fitted values for each fitness component.
```{r, warning = FALSE, results='hide', message=FALSE, error = FALSE, eval=FALSE}
model.fitness.components.bayes <- brm(g | se(SE)  ~ Outcome #Note that running se(SE, sigma = TRUE) gives different result due to a difference in priors
                + (1|Study.ID)
                + (1|Taxon), 
                family = "gaussian", 
                seed = 1,
                cores = 4, chains = 4, iter = 4000, #Run 4 chains in parallel for 4000 iterations (2000 are burn in)
                control = list(adapt_delta = 0.999, max_treedepth = 15),
                data = prelim.data %>% mutate(SE = sqrt(var.g)))

make_text_summary(model.fitness.components.bayes) %>% add_significance_stars() %>% tibble::rownames_to_column("Model Parameter") %>% pander(split.cell = 40, split.table = Inf)

saveRDS(model.fitness.components.bayes, "data/components.brms.rds") #Save to avoid re-running during knit
```

**Table S6** Summary of model predictions for 20 fitness components. In the manuscript these values are presented as a text overlay on Figure 1 (Forest Plot). Additionally, Bayes Factors (BF) are presented as the likelihood ratio that the effect size is greater than 0. Where values greater than 1 correspond to higher likelihood of the effect size being positive and values less than 1 suggest that the effect size is more likely to be negative.

```{r, warning = FALSE}
components.brms <- readRDS(file = "data/components.brms.rds") #Avoid re-running model above

#Expand grid for environment and sex
brms.newdata <- as.data.frame(expand.grid(Outcome = unique(prelim.data$Outcome)))

#Get average SE: useful if using predict, but not fitted
av.se.g <- prelim.data %>% group_by(Outcome) %>% summarise(mean = mean(sqrt(var.g)))
brms.newdata$SE <- av.se.g$mean

#Add predictions/fitted values
brms.predict <- fitted(components.brms, newdata = brms.newdata, re_formula = NA)
brms.predict <- as.data.frame(brms.predict)
brms.predictions <- data.frame(brms.newdata$Outcome, brms.predict$Estimate, brms.predict$Est.Error, brms.predict$Q2.5, brms.predict$Q97.5)

#Name columns
colnames(brms.predictions) <- c("Fitness Component", "Estimate", "Error", "LCI", "UCI")

outcome.list.factor <-  c('Behavioural Plasticity', 'Body Size', 'Development Rate', 'Early Fecundity', 'Immunity', 'Mating Duration', 'Pesticide Resistance', 'Mutant Frequency', 'Body Condition', 'Fitness Senescence', 'Lifespan', 'Male Attractiveness', 'Mating Frequency', 'Mating Latency', 'Mating Success', 'Strength', 'Ejaculate Quality and Production', 'Extinction Rate', 'Offspring Viability', 'Reproductive Success')

brms.predictions <- brms.predictions[match(outcome.list.factor, brms.predictions$`Fitness Component`),]
rownames(brms.predictions) <- NULL
sample.sizes.outcomes <- as.data.frame(table(prelim.data$Outcome))
colnames(sample.sizes.outcomes) <- c("Fitness Component", "n")
fitness.component.predictions <- left_join(brms.predictions, sample.sizes.outcomes, by = "Fitness Component")

#Obtain Bayes Factor of likelihood that the outcome is greater than 0
BF.outcome.list <-  c('Body Size', 'Development Rate', 'Early Fecundity', 'Immunity', 'Mating Duration', 'Pesticide Resistance', 'Mutant Frequency', 'Body Condition', 'Fitness Senescence', 'Lifespan', 'Male Attractiveness', 'Mating Frequency', 'Mating Latency', 'Mating Success', 'Strength', 'Ejaculate Quality and Production', 'Extinction Rate', 'Offspring Viability', 'Reproductive Success')
#Obtain BF for all components
Hypotheses <- list()
BFs <- list()
Hypotheses[["Behavioural Plasticity"]] <- hypothesis(components.brms, "Intercept > 0") #Intercept in model, need to do it by itself
BFs[["Behavioural Plasticity"]] <- Hypotheses[["Behavioural Plasticity"]][["hypothesis"]][["Evid.Ratio"]]
for (i in BF.outcome.list){
Hypotheses[[i]] <- hypothesis(components.brms, paste("Intercept + Outcome",i," > 0", sep = ""))
BFs[[i]] <- Hypotheses[[i]][["hypothesis"]][["Evid.Ratio"]]
} #Loop for all fitness compoinents
fitness.component.predictions %>% cbind.data.frame(as.data.frame(BFs) %>% t() %>% as.data.frame() %>% `colnames<-`("BF")) %>% add_significance_stars2() %>% pander(split.cell = 40, split.table = Inf, digits = 2)
```

____________________

### Models With Many Covariates

We collected data from fitness components that were deemed ambiguous as well as unambiguous. The ambiguous outcomes are likely to add in heterogeneity to the models and may not help us in answering questions of the fitness effects of sexual selection. A REML model utilising our complete dataset with many moderator variables would thus be: 

<input type=button class=hideshow></input>
```{r}
model.preliminary <- rma.mv(g, var.g, 
                         mods = ~ 1 + Sex * Environment + Taxon + Outcome.Class + log(Generations) + Blinding, # << ----- Add big model, then cull predictors to this one
                         random = list(~ 1 | Study.ID, 
                                       ~ 1 | Outcome), 
                         method = "REML", 
                         data = prelim.data)

summary(model.preliminary, digits = 2)
```
<br></br>
Here we can also run a Bayesian model alongside the REML model (metafor). The _R^2^_ for this model is 0.36 (95% CIs = 0.33-0.4). 
```{r, warning = FALSE, results='hide', message=FALSE, error = FALSE, eval=FALSE}
#Also use bayesian model
brms.preliminary <- brm(g | se(SE)  ~ 1 + Sex * Environment + log(Generations) + Blinding #Note that running se(SE, sigma = TRUE) gives different result due to a difference in priors
                + (1|Study.ID) #group level effects
                + (1|Outcome)
                + (1|Taxon), 
                family = "gaussian", 
                seed = 1,
                cores = 4, chains = 4, iter = 4000, #Run 4 chains in parallel for 4000 iterations (2000 are burn in)
                control = list(adapt_delta = 0.999, max_treedepth = 15),
                data = prelim.data %>% mutate(SE = sqrt(var.g)))

```
<br></br>
<input type=button class=hideshow></input>
```{r}
brms.preliminary <- readRDS(file = "data/brms.preliminary.rds") #Avoid re-running model above
#Plot model results
prelim.results.bayesplot <- bayesplot::mcmc_areas(posterior_samples(brms.preliminary)[,1:11]) + 
  geom_vline(xintercept = 0, linetype = 2) +
  
  theme_bw()+
  
  theme(panel.spacing = unit(0.1, "lines"),
        text = element_text(size=16),
        panel.border= element_blank(),
        axis.line=element_line(), 
        panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        panel.grid.minor.x = element_blank(), 
        legend.text = element_text(size=16), 
        legend.title=element_text(size=16, 
                                  face = "bold"),
        axis.title.x = element_text(hjust = 0.5, size = 14),
        axis.title.y = element_text(size = 16, hjust = 0.35, margin = margin(r=-10)),
        axis.text.y = element_text(angle = 0),
        plot.title = element_text(size = 16))

prelim.results.bayesplot

make_text_summary(brms.preliminary) %>% add_significance_stars() %>% tibble::rownames_to_column("Model Parameter") %>% pander()
```
**Figure S2 & Table S7:** Bayesian model results for a preliminary model that explores many covariates collected in the dataset.

From these models we can see that there are several redundant moderators: Blinding and Generations show little effect and are not key to our research question (like sex and environment are). However, because taxa is a likely source of heterogeneity and effect size could reasonably be expected to differ between taxa, we investigate taxa as a fixed effect.

____________________

### Sexual Selection Amongst Taxa

First we want to run the model using a restricted dataset where we remove effect sizes with Ambiguous outcomes (directionless or variable in their relation to fitness) or environments that were not stated whether they were stressed or unstressed (confusing and confounding). Notably, with the ambiguous measures included we already see a positive effect of sexual selection and thus removing these fitness components is not an attempt to obtain a significant answer, rather it restricts the data to traits that are less contentious and thus we believe this approach is conservative. In this model we use Sex, Environment, Taxon and the interaction between sex and environment.

<input type=button class=hideshow></input>
```{r, message=FALSE, error = FALSE, warning=FALSE}
#Restrict the dataset for unambiguous outcomes and environments 
restricted.data <- prelim.data %>% 
  filter(Outcome.Class != "Ambiguous" & Environment != "Not Stated") %>% 
  mutate(Sex = as.character(Sex), 
         Environment = as.character(Environment), 
         Outcome.Class.2 = as.character(Outcome.Class), 
         Enforced.Monogamy = as.character(Enforced.Monogamy))

# Make sure the factors are leveled in the same order as we write our prediction function (below)
restricted.data$Environment <- restricted.data$Environment %>% factor() %>% relevel(ref="Unstressed")
restricted.data$Sex <- restricted.data$Sex %>% factor() %>% relevel(ref="M")
restricted.data$Outcome.Class <- restricted.data$Outcome.Class %>% factor() %>% relevel(ref="Indirect")
restricted.data$Taxon <- relevel(restricted.data$Taxon, ref = "Beetle") 
restricted.data$Outcome <- restricted.data$Outcome %>% factor()

model.complete <- rma.mv(g, V = var.g, 
                         mods = ~ 1 + Sex * Environment + Taxon, # << ----- Add big model, then cull predictors to this one
                         random = list(~ 1 | Study.ID, 
                                       ~ 1 | Outcome), 
                         method = "REML", 
                         data = restricted.data)

summary(model.complete, digits = 2)
```

The result is a model with estimates for various taxa, species, sexes and environments. To make sense of these estimates we should obtain average predictions for each moderator variable class of interest. We can do that by using a modified version version of a function used by @Holman_2018. Here it alows us to cluster predictions for the different moderators of interest: Sex, environment, taxon etc. This is done by obtaining predictions using the base ``predict()`` function for the ``rma.mv()`` objects that have been previously created
```{r, warning=FALSE, fig.height= 8, fig.width=8}
# function that makes predict.rma work like a normal predict() function, instead of the idiosyncratic way that it works by default.
get.predictions.complete <- function(newdata){
  B<-0; F<-0; Stressed<-0; Cricket<-0; Fly<-0; Guppy<-0; Mite<-0; Mouse<-0; interaction1<-0; interaction2<-0; interaction3<-0
  if(newdata[1] == "B") B<-1 
  if(newdata[1] == "F") F<-1 
  if(newdata[2] == "Stressed") Stressed<-1
  if(newdata[3] == "Cricket") Cricket<-1
  if(newdata[3] == "Fly") Fly<-1
  if(newdata[3] == "Guppy") Guppy<-1
  if(newdata[3] == "Mite") Mite<-1
  if(newdata[3] == "Mouse") Mouse<-1
  if(newdata[1] == "B" & newdata[2] == "Stressed") interaction1<-1
  if(newdata[1] == "F" & newdata[2] == "Stressed") interaction2<-1

  predict(model.complete, newmods=c(B, F, Stressed, Cricket, Fly, Guppy, Mite, Mouse, interaction1=interaction1, interaction2=interaction2))
}
# Get the predictions for each combination of moderators
predictions.complete <- as.data.frame(expand.grid(Sex = c("M", "B", "F"),
                           Environment = c("Unstressed", "Stressed"),
                           Taxon = c("Beetle", "Cricket", "Fly", "Guppy", "Mite", "Mouse")))
predictions.complete <- cbind(predictions.complete, do.call("rbind", apply(predictions.complete, 1, get.predictions.complete))) %>%
  select(Sex, Environment, Taxon, pred, se, ci.lb, ci.ub) 
for(i in 4:7) predictions.complete[,i] <- unlist(predictions.complete[,i])

countpred = count_(restricted.data, c("Sex", "Environment", "Taxon"))

predictions.complete <- left_join(predictions.complete, countpred, by = c("Sex", "Environment", "Taxon"))

countpred = count_(restricted.data, c("Sex", "Environment", "Taxon"))

predictions.complete <- left_join(predictions.complete, countpred, by = c("Sex", "Environment", "Taxon"))



#Thirdly, plot the model predictions for effect size (Hedges' g) for male, female and both sexes under both stressed and unstressed condition and faceted for each taxon. 


pd <- position_dodgev(0.6)

Taxon.metaanlysis <- predictions.complete %>% 
    mutate(Sex = replace(as.character(Sex), Sex == "B", "Both"),
         Sex = replace(Sex, Sex == "M", "Male"),
         Sex = replace(Sex, Sex == "F", "Female"),
         Environment = replace(as.character(Environment), Environment == "Stressed", "Stressful"),
         Environment = replace(Environment, Environment == "Unstressed", "Benign"),
         Sex = factor(Sex, levels = c("Male", "Both", "Female"))) %>%
  ggplot(aes(x = pred, y= Environment, fill = Sex)) + 
  geom_vline(xintercept = 0, linetype = 2, colour = "black") + 
  geom_errorbarh(aes(xmin = predictions.complete$ci.lb, 
                     xmax = predictions.complete$ci.ub,
                     color= Sex), 
                 height = 0, position = pd, show.legend = F) +
  geom_point(position = pd, size=2, shape=21, color = "grey20") + 
  facet_grid(Taxon ~.)+
  ylab("Environment \n")+
  xlab("\nModel Prediction (Hedges g)")+
  xlim(-1, 2)+
  ggtitle('Effects of Sex and Stress on \nPopulation Fitness for Each Taxon')+
  scale_fill_manual(values = c("Male" = "#e41a1c", "Female" = "#377eb8", "Both" = "#4daf4a"))+
  scale_color_manual(values = c("Male" = "#e41a1c", "Female" = "#377eb8", "Both" = "#4daf4a"))+
  guides(fill = guide_legend(reverse=T, override.aes = list(size = 4.5)))+
  
    theme_bw()+
  
  theme(strip.text.y = element_text(angle = 0, size = 14, margin = margin(r=20, l=20)), 
        strip.background = element_rect(colour = NULL,
                                        linetype = "blank",
                                        fill = "gray90"),
        text = element_text(size=14),
        panel.spacing = unit(0.5, "lines"),
        panel.border= element_blank(),
        axis.line=element_line(), 
        panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        panel.grid.minor.x = element_blank(), 
        legend.text = element_text(size=14), 
        legend.title=element_text(size=14, 
                                  face = "bold"),
        axis.title.x = element_text(hjust = 0.3, size = 14),
        axis.title.y = element_text(size = 14),
        plot.title = element_text(size = 14))

#ggsave(plot = Taxon.metaanlysis, filename = "figures/Taxon_metaanalysis_plot.svg", height = 8, width = 8)
Taxon.metaanlysis
```
<br></br>
**Figure S3:** The predictions from this model indicate some heterogeneity between taxon. However, the most apparent difference between taxa is that confidence bands increase for taxa with low sample size. As previously shown, the beetle and fly taxa are the most heavily sampled and in the above figure have the narrowest confidence bands. Importantly, the overall direction of effect does not change between taxon, although guppies and mice show near zero effect sizes. Here we see that under stressed environments, females from all taxa appear to have greater fitness increase than males or 'both'. 


**Table S8** The predictions for the above figure looking at the effect of sexual selection amongst taxa uses the following dataframe. 

```{r}
colnames(predictions.complete) <- c("Sex", "Environment", "Taxon", "Prediction", "SE", "CI.lb", "CI.ub", "n")
predictions.complete <- format(predictions.complete, digits = 2)
predictions.complete[[9]] <- NULL
predictions.complete %>% pander()
```

Given that none of categories of taxa significantly impact effect size, and many categories are unsamples (Table S8) we can incorporate them as random/group level effects in models henceforth.

____________

###REML: Effects of Environment and Sex

Here we ask two key questions: Does sexual selection benefit populations in stressful environments more than benign environments? **AND** Do the benefits of sexual selection differ between the sexes?

```{r}
#We can run a model where the outcome is crossed with study (Study.ID) and Taxon as random effects and environment, sex and their interactions are fixed effects.
model.complete2 <- rma.mv(g, V = var.g, 
                          mods = ~ 1 + Sex * Environment, 
                          random = list(~ 1 | Study.ID, 
                                       ~ 1 | Outcome,
                                       ~ 1 | Taxon), 
                          method = "REML", 
                          data = restricted.data)
summary(model.complete2, digits = 2)
```


We conducted hypothesis tests on the above model to investigate the effective difference between two groups. Depending on the package this method is also refered to as linear hypothesis or anova (metafor). 


**Table S9** Using the ``anova.rma`` function we can conduct hypothesis tests between two categorical groups in the model. Here we conduct 5 tests testing relative effects of sexual selection between the sexes and in different environments. 

```{r}
#anova where you specify the values based on the list of moderators
anova.1 = anova(model.complete2, L=c(0, 0, -1, 0, 0, 0)) 
anova.2 = anova(model.complete2, L=c(0, 0, -1, 0, 0, -1))
anova.3 = anova(model.complete2, L=c(0, 0, 0, -1, 0, -1))
anova.4 = anova(model.complete2, L=c(0, 0, 0, -1, 0, 0))
anova.5 = anova(model.complete2, L=c(0, 0, 0, -1, -1, 0))

anova.list <- list(anova.1, anova.2, anova.3, anova.4, anova.5)

anova.frame <- t(data.frame(lapply(anova.list, function(x) {
  data.frame(x[["hyp"]],
  x[["Lb"]],
  x[["se"]],
  x[["Lb"]] - 1.96*x[["se"]],
  x[["Lb"]] + 1.96*x[["se"]],
  x[["pval"]])
})))
anova.frame <- as.data.frame(split(anova.frame, rep(1:6)))
colnames(anova.frame) <- c("Hypothesis", "Estimate", "Est.Error", "CI.Lower", "CI.Upper", "pval")
anova.frame$Estimate <- as.numeric(levels(anova.frame$Estimate))[anova.frame$Estimate]
anova.frame$Est.Error <- as.numeric(levels(anova.frame$Est.Error))[anova.frame$Est.Error]
anova.frame$CI.Lower <- as.numeric(levels(anova.frame$CI.Lower))[anova.frame$CI.Lower]
anova.frame$CI.Upper <- as.numeric(levels(anova.frame$CI.Upper))[anova.frame$CI.Upper]
anova.frame$pval <- as.numeric(levels(anova.frame$pval))[anova.frame$pval]
anova.frame <- format(anova.frame, digits = 2)
anova.frame$star <- c("", "*", "*", "*", "")
colnames(anova.frame)[colnames(anova.frame)=="star"] <- " "
anova.frame$pval <- NULL
rownames(anova.frame) <- c("M vs F, Benign", "M vs F, Stressful", "Benign vs Stressful, Female", "Benign vs Stressful, Male", "Benign vs Stressful, Both")
anova.frame %>% pander(split.table = Inf)
```
<br></br>
From these anovas we see that a stressful environment leads to a significantly greater increase in fitness components for "female"" but NOT "both" sexes, while significantly decreasing male fitness. We also see there is a difference between the sexes in stressful environments (females with larger mean) but not in benign environments (marginal).

______________

###Bayesian: Effects of Environment and Sex

We can run a Bayesian model using the ``brms`` package. The model has the same moderators as the REML approach used above. The ``brms`` package sets standard priors that are selected to be 'weakly informative'. The _R^2^_ of this Bayesian model was 0.35 (95% CIs = 0.31-0.39). Additionally, we can obtain the distribution of posterior fitted values and examine the model summary

```{r, warning = FALSE, results='hide', message=FALSE, error = FALSE, eval=FALSE}
#Use brms to create a model similar to the one used in the REML approach. 
brms.complete2 <- brm(g | se(SE)  ~ 1 + Sex * Environment #se(SE, sigma = TRUE) gives differnt results
                + (1|Taxon) #group level effect #1
                + (1|Study.ID) #group level effect #2
                + (1|Outcome), #group level effect #3 
                family = "gaussian", 
                seed = 1,
                cores = 4, chains = 4, iter = 4000, # Run 4 chains in parallel for 4000 iterations (2000 are burn in)
                control = list(adapt_delta = 0.9999, max_treedepth = 15),
                data = restricted.data %>% mutate(SE = sqrt(var.g)))

```
<br></br>

**Table S10** Model estimate summary table for the Bayesian model investigating the effect of environment and sex (alongside sexual selection) on fitness. 
```{r}
brms.complete2 <- readRDS(file = "data/brms.complete2.rds") #Avoid re-running model above

#You can obtain a posterior sampling through the ``fitted.brmsfit`` function, which gives the same posterior values as doing it manually (see below).**Note that the fitted values obtained here have much smaller error than the predict values**


# #obtain average variance of each group in the prediction
# av.var.g <- as.numeric(c(restricted.data %>% filter (Sex == 'M' & Environment == "Unstressed") %>% summarise(mean = mean(var.g)),
#               restricted.data %>% filter (Sex == 'B' & Environment == "Unstressed") %>% summarise(mean = mean(var.g)),
#               restricted.data %>% filter (Sex == 'F' & Environment == "Unstressed") %>% summarise(mean = mean(var.g)),
#               restricted.data %>% filter (Sex == 'M' & Environment == "Stressed") %>% summarise(mean = mean(var.g)),
#               restricted.data %>% filter (Sex == 'B' & Environment == "Stressed") %>% summarise(mean = mean(var.g)),
#               restricted.data %>% filter (Sex == 'F' & Environment == "Stressed") %>% summarise(mean = mean(var.g))))

#Expand grid for environment and sex
# brms.newdata <- as.data.frame(expand.grid(Sex = c("M", "B", "F"),
#                            Environment = c("Unstressed", "Stressed")))
# #Add variance
# brms.newdata$var.g <- av.var.g
# 
# #Add predictions
# brms.predict <- fitted(meta.brms, newdata = brms.newdata, re_formula = NA)
# brms.predict <- as.data.frame(brms.predict)
# brms.predictions <- data.frame(brms.newdata$Sex, brms.newdata$Environment, brms.predict$Estimate, brms.predict$Est.Error, brms.predict$Q2.5, brms.predict$Q97.5)
# 
# #Name columns
# colnames(brms.predictions) <- c("Sex", "Environment", "Estimate", "Error", "LCI", "UCI")


#Alternatively you can obtain posterior samples manually.
post <- (posterior_samples(brms.complete2, 
                           pars = c("b_Intercept", "b_SexB", "b_SexF", 
                                    "b_EnvironmentStressed", "b_SexB:EnvironmentStressed", 
                                    "b_SexF:EnvironmentStressed")) %>%
         mutate(both_benign = b_Intercept + b_SexB,
         both_stressful = b_Intercept + b_SexB + b_EnvironmentStressed + `b_SexB:EnvironmentStressed`,
         male_benign = b_Intercept,
         male_stressful = b_Intercept + b_EnvironmentStressed,
         female_benign = b_Intercept + b_SexF,
         female_stressful = b_Intercept + b_SexF + b_EnvironmentStressed + `b_SexF:EnvironmentStressed`))[,-(1:6)]


#Obtain posterior fitted values and transform
# posterior_fit <- data.frame(t(posterior_linpred(meta.brms, newdata = brms.newdata, re_formula = NA)))

#Add columns for Environment and Sex
post <- as.data.frame(t(post))
post$Sex <- c("Both", "Both", "Male", "Male", "Female", "Female")
post$Environment <- c("Benign", "Stressful", "Benign", "Stressful", "Benign", "Stressful")

#Clean up dataframe
post <- melt(post, id = c("Sex", "Environment"))
post$variable <- NULL

make_text_summary(brms.complete2) %>% add_significance_stars() %>% tibble::rownames_to_column("Model Parameter") %>% pander()
```
<br></br>
Like with the REML approach, from these model results we can test several hypotheses between the categories of environment and sex.

**Table S11** Hypothesis tests for the Bayesian model are similar to the REML model (Table S9), with slight differences to CIs.
```{r}
#Obtain hypothesis estimates
brms.hypothesis <- hypothesis(brms.complete2, c("0 = SexF",
                             "0 = SexF + SexF:EnvironmentStressed",
                             "0 = SexF:EnvironmentStressed + EnvironmentStressed",
                             "0 = EnvironmentStressed",
                             "0 = SexB:EnvironmentStressed + EnvironmentStressed"))
#Format into dataframe
brms.hypothesis.table <- 
  data.frame(brms.hypothesis[["hypothesis"]][["Hypothesis"]],
             brms.hypothesis[["hypothesis"]][["Estimate"]],
             brms.hypothesis[["hypothesis"]][["Est.Error"]],
             brms.hypothesis[["hypothesis"]][["CI.Lower"]],
             brms.hypothesis[["hypothesis"]][["CI.Upper"]],
             brms.hypothesis[["hypothesis"]][["Star"]])
colnames(brms.hypothesis.table) <- c("Hypothesis", "Estimate", "Est.Error", "CI.Lower", "CI.Upper", " ")
brms.hypothesis.table <- format(brms.hypothesis.table, digits = 2)
rownames(brms.hypothesis.table) <- c("M vs F, Benign", "M vs F, Stressful", "Benign vs Stressful, Female", "Benign vs Stressful, Male", "Benign vs Stressful, Both")
brms.hypothesis.table %>% pander(split.table = Inf)
```
<br></br>
Using predictions from both REML and Bayesian models we can obtain a figure that plots the mean/median predictions as well as distribution density (Bayesian) and 95 % CI (REML).

```{r, fig.height=6, fig.width=6, warning=FALSE, message=FALSE, error = FALSE}
#Generate predictions without taxon utilising the previously described function

get.predictions.complete2 <- function(newdata){
  B<-0; F<-0; Stressed<-0; interaction1<-0; interaction2<-0; interaction3<-0
  if(newdata[1] == "B") B<-1 
  if(newdata[1] == "F") F<-1 
  if(newdata[2] == "Stressed") Stressed<-1
  if(newdata[1] == "B" & newdata[2] == "Stressed") interaction1<-1
  if(newdata[1] == "F" & newdata[2] == "Stressed") interaction2<-1

  predict(model.complete2, newmods=c(B, F, Stressed, interaction1=interaction1, interaction2=interaction2))
}

# Get the predictions for each combination of moderators
predictions.complete2 <- as.data.frame(expand.grid(Sex = c("M", "B", "F"),
                           Environment = c("Unstressed", "Stressed")))
predictions.complete2 <- cbind(predictions.complete2, do.call("rbind", apply(predictions.complete2, 1, get.predictions.complete2))) %>%
  select(Sex, Environment, pred, se, ci.lb, ci.ub) 
for(i in 3:6) predictions.complete2[,i] <- unlist(predictions.complete2[,i])

countpred <- count_(restricted.data, c("Sex", "Environment"))

predictions.complete2 <- left_join(predictions.complete2, countpred, by = c("Sex", "Environment"))
colnames(predictions.complete2) <- c("Sex", "Environment", "Prediction", "SE", "CI.lb", "CI.ub", "n")
predictions.complete2 <- predictions.complete2 %>%
      mutate(Sex = replace(as.character(Sex), Sex == "B", "Both"),
         Sex = replace(Sex, Sex == "M", "Male"),
         Sex = replace(Sex, Sex == "F", "Female"),
         Environment = replace(as.character(Environment), Environment == "Stressed", "Stressful"),
         Environment = replace(Environment, Environment == "Unstressed", "Benign"),
         Sex = factor(Sex, levels = c("Male", "Both", "Female")))

#Plot the posterior values from the Bayesian model as density ridges
pd <- position_dodgev(height = 0.3)
posterior.plot <- post %>% mutate(Sex = factor(Sex, levels = c("Male", "Both", "Female"))) %>% ggplot()+
  stat_density_ridges(aes(x=value, y = Environment, fill = Sex), alpha = 0.65, scale = 0.6, position = position_nudge(y = 0.15), height = 10, show.legend = F, quantile_lines = T, quantiles = 2)+
  geom_vline(xintercept = 0, linetype = 2, colour = "black") + 
    ylab("Environment")+
  xlab("\nEffect Size (Hedges' g)")+
  scale_fill_manual(values = c("Male" = "#e41a1c", "Female" = "#377eb8", "Both" = "#4daf4a"))+
  scale_color_manual(values = c("Male" = "#e41a1c", "Female" = "#377eb8", "Both" = "#4daf4a"))+
  scale_x_continuous(limits = c(-0.75, 1.5), breaks = c(-1, -.5, 0, 0.5, 1, 1.5))+
  
  theme_bw()+
  
  theme(panel.spacing = unit(0.1, "lines"),
        text = element_text(size=16),
        panel.border= element_blank(),
        axis.line=element_line(), 
        panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        panel.grid.minor.x = element_blank(), 
        legend.text = element_text(size=16), 
        legend.title=element_text(size=16, 
                                  face = "bold"),
        axis.title.x = element_text(hjust = 0.5, size = 14),
        axis.title.y = element_text(size = 16, hjust = 0.35, margin = margin(r=-10)),
        axis.text.y = element_text(angle = 0),
        plot.title = element_text(size = 16))

#Add the REML predictions as circles with error bars
both.plots <- posterior.plot + 
  geom_errorbarh(data = predictions.complete2 %>% mutate(Sex = factor(Sex, levels = c("Male", "Both", "Female"))), 
                 aes(x= Prediction, xmin = predictions.complete2$CI.lb,
                     xmax = predictions.complete2$CI.ub, y = Environment,
                     color = Sex), 
                 height = 0, show.legend = F, position = pd)+
  
  geom_point(data = predictions.complete2 %>% mutate(Sex = factor(Sex, levels = c("Male", "Both", "Female"))), 
             aes(x = Prediction, y = Environment, size=n, fill = Sex), 
             shape=21, color = "grey20", position = pd) +
  
    guides(fill = guide_legend(reverse=T, override.aes = list(size = 7.5)))+
    scale_size(guide = 'none')+
  
  scale_y_discrete(expand=c(0.075,0))
  
# svg("figures/both_plot.svg", width=6, height=6)
# both.plots
# dev.off()
# #
# pdf("figures/both_plot.pdf",  width = 6, height = 6)
# both.plots
# dev.off()

both.plots
```
<br></br>
**Figure S3:** Sexual selection generally increases population fitness, especially for females under stressful conditions. The benefits of sexual selection on fitness for females under stressful conditions are small-medium according to Cohen's interperetation of effect sizes. Circle size is proportional to sample size (shown below). The REML predictions are shown as circles with error bars and the Bayesian predictions as density ridges. This figure can also be found in the main manuscript. 


**Table S12** The REML predictions in the plot above use the following dataframe
```{r}
predictions.complete2 <- format(predictions.complete2, digits = 2)
predictions.complete2$Prediction = as.numeric(predictions.complete2$Prediction)
predictions.complete2$CI.lb = as.numeric(predictions.complete2$CI.lb)
predictions.complete2$CI.ub = as.numeric(predictions.complete2$CI.ub)
predictions.complete2$n = as.numeric(predictions.complete2$n)

predictions.complete2 %>% pander()
```


____________________

###Estimating Hedges' g Heterogeneity Using _I^2^_

Using an adapted function from https://github.com/daniel1noble/metaAidR we can obtain confidence intervals for total _I^2^_ and the individual components of the random effects. There are different methods to obtain estimates of _I^2^_. Here we obtain an overall value of _I^2^_ that is weighted based on variance and where estimates of heterogeneity are sourced from sigma^2^ of the respective models. The values are based on the REML models. 

```{r}
I2(model.complete2, restricted.data$var.g) %>% pander(digits = 3)
```
These values indicate that 61.5 % of total heterogeneity is due to the **between study** heterogeneity and 33.5 % for **between outcome** heterogeneity between different outcomes. The total _I^2^_  is 95 %, a reasonably high _I^2^_ value. However this is relatively common in Ecology and Evolution total. 

____________________

##Meta-Analysis on Variance

###Obtaining lnCVR and Meta-Analysis Models

This meta-analysis on variation utilises previously described and utilised methods devoleped [@Nakagawa_2015; @Senior_2016]. Our goal is to determine whether the phenotypic variance in fitness related traits is impacted by sexual selection. We would assume that if selection is occuring not only would the trait mean shift in a certain direction but the variance associated with those changes to the mean would also decrease. In this case we use an effect size statistic known as the natural log of the coefficient of variation ratio (lnCVR).

```{r}
# Firstly, we setup our calculation by creating a a restricted dataset with only unabmiguous fitness outcomes and running the functions developed by Nakagawa et al. 2015: 
Calc.lnCVR<-function(CMean, CSD, CN, EMean, ESD, EN){
	
	ES<-log(ESD) - log(EMean) + 1 / (2*(EN - 1)) - (log(CSD) - log(CMean) + 1 / (2*(CN - 1)))
	
	return(ES)
	
}

#for variance of lnCVR

Calc.var.lnCVR<-function(CMean, CSD, CN, EMean, ESD, EN, Equal.E.C.Corr=T){
	
	if(Equal.E.C.Corr==T){
	
		mvcorr<-cor.test(log(c(CMean, EMean)), log(c(CSD, ESD)))$estimate
	
		S2<- CSD^2 / (CN * (CMean^2)) + 1 / (2 * (CN - 1)) - 2 * mvcorr * sqrt((CSD^2 / (CN * (CMean^2))) * (1 / (2 * (CN - 1)))) + ESD^2 / (EN * (EMean^2)) + 1 / (2 * (EN - 1)) - 2 * mvcorr * sqrt((ESD^2 / (EN * (EMean^2))) * (1 / (2 * (EN - 1))))
	
	}
	else{
		
		Cmvcorr<-cor.test(log(CMean), log(CSD))$estimate
		Emvcorr<-cor.test(log(EMean), (ESD))$estimate
	
		S2<- CSD^2 / (CN * (CMean^2)) + 1 / (2 * (CN - 1)) - 2 * Cmvcorr * sqrt((CSD^2 / (CN * (CMean^2))) * (1 / (2 * (CN - 1)))) + ESD^2 / (EN * (EMean^2)) + 1 / (2 * (EN - 1)) - 2 * Emvcorr * sqrt((ESD^2 / (EN * (EMean^2))) * (1 / (2 * (EN - 1))))		
		
		
	}
	return(S2)
	
}


# Secondly, we utilise those formulas to obtain lnCVR and var.CVR for all applicable effect sizes. Noting that not all of the dataset has means, SD and n; some were calculated from summary statistics and are not able to have lnCVR calculated:

#Calculate lnCVr and var.lnCVr
#for lnCVR
restricted.data$lnCVr <- Calc.lnCVR(restricted.data$mean.low, restricted.data$sd.low, restricted.data$n.low, restricted.data$mean.high, restricted.data$sd.high, restricted.data$n.high)

#for variance in lnCVR
restricted.data$var.lnCVr <- Calc.var.lnCVR(restricted.data$mean.low, restricted.data$sd.low, restricted.data$n.low, restricted.data$mean.high, restricted.data$sd.high, restricted.data$n.high, Equal.E.C.Corr=T) #Equal.E.C.Corr = T assumes that the correlaiton between mean and sd (Taylor's Law) is equal for the mean and control groups


restricted.data2 <- restricted.data 
```

Although not previously done extensively, it seems that the best way to conduct this analysis is not through subsetting but through utilising model predictions as we did with Hedges' g previously, that way we retain the same methodology in model structure and test the same hypotheses. This can be done be utilising the same predict function but for lnCVR and var.lnCVR. For the brms model we can obtain predictions manually or through the ``fitted.brmsfit``.

Multilevel-model using lnCVR and REML:

```{r, warning=FALSE}
variance.model <- rma.mv(lnCVr, V = var.lnCVr, mods = ~ 1 + Sex*Environment, 
                          random = list(~ 1 | Taxon,
                                        ~ 1 | Study.ID,
                                        ~ 1 | Outcome), 
                         method = "REML", data = restricted.data2)
summary(variance.model, digits = 2)
```
<br></br>

Again, we use ``brms`` to obtain Bayesian model estimates. For this model the _R^2^_ is 0.34 (95% CIs = 0.32-0.36).
```{r, warning = FALSE, results='hide', message=FALSE, error = FALSE, eval=FALSE}
#When knitting this markdown this model stalls
#Use brm to create a model similar to the one used in the REML approach. 
variance.brms <- brm(lnCVr| se(SE.v)  ~ 1 + Sex * Environment #response is Hedges' g and the standard error associated with it (SE), sex, environment and their interaction are moderators
                + (1|Taxon) #group level effects
                + (1|Study.ID)
                + (1|Outcome),
                family = "gaussian", #default
                seed = 1,
                cores = 4, chains = 4, iter = 4000, #Run 4 chains in parrallel for 4000 iterations (2000 are burn in)
                control = list(adapt_delta = 0.999, max_treedepth = 15),
                data = restricted.data2 %>% mutate(SE.v = sqrt(var.lnCVr)))
```
**Table S13** Model estimates, including random effect sigma value for the model of phenotypic variance (lnCVR)
```{r}
var.brms <- readRDS(file = "data/variance.brms.rds") #Avoid re-running model above
post.variance <- (posterior_samples(var.brms, 
                           pars = c("b_Intercept", "b_SexB", "b_SexF", 
                                    "b_EnvironmentStressed", "b_SexB:EnvironmentStressed", 
                                    "b_SexF:EnvironmentStressed")) %>%
         mutate(both_benign = b_Intercept + b_SexB,
         both_stressful = b_Intercept + b_SexB + b_EnvironmentStressed + `b_SexB:EnvironmentStressed`,
         male_benign = b_Intercept,
         male_stressful = b_Intercept + b_EnvironmentStressed,
         female_benign = b_Intercept + b_SexF,
         female_stressful = b_Intercept + b_SexF + b_EnvironmentStressed + `b_SexF:EnvironmentStressed`))[,-(1:6)]

#Add columns for Environment and Sex
post.variance <- as.data.frame(t(post.variance))
post.variance$Sex <- c("Both", "Both", "Male", "Male", "Female", "Female")
post.variance$Environment <- c("Benign", "Stressful", "Benign", "Stressful", "Benign", "Stressful")

#Clean up dataframe
post.variance <- melt(post.variance, id = c("Sex", "Environment"))
post.variance$variable <- NULL


make_text_summary(var.brms) %>% add_significance_stars() %>% tibble::rownames_to_column("Model Parameter") %>% pander()
```
<br></br>
Predictions based on the REML and Bayesian model can then be generated in the same way as for Hedges'g. Here, negative values of lnCVR indicate a narrowing (decrease) in phenotypic variance as a result of sexual selection.

```{r, fig.height=6, fig.width=6, warning =FALSE, message=FALSE, error = FALSE}

#Generate predictions
get.predictions.variance <- function(newdata){
  B<-0; F<-0; Stressed<-0; interaction1<-0; interaction2<-0; interaction3<-0
  if(newdata[1] == "B") B<-1 
  if(newdata[1] == "F") F<-1 
  if(newdata[2] == "Stressed") Stressed<-1
  if(newdata[1] == "B" & newdata[2] == "Stressed") interaction1<-1
  if(newdata[1] == "F" & newdata[2] == "Stressed") interaction2<-1

  predict(variance.model, newmods=c(B, F, Stressed, interaction1=interaction1, interaction2=interaction2))
}
# Get the predictions for each combination of moderators
predictions.variance <- as.data.frame(expand.grid(Sex = c("M", "B", "F"),
                           Environment = c("Unstressed", "Stressed")))
predictions.variance <- cbind(predictions.variance, do.call("rbind", apply(predictions.variance, 1, get.predictions.variance))) %>%
  select(Sex, Environment, pred, se, ci.lb, ci.ub) 
for(i in 3:6) predictions.variance[,i] <- unlist(predictions.variance[,i])

countpred = count_(restricted.data2, c("Sex", "Environment"))

predictions.variance <- left_join(predictions.variance, countpred, by = c("Sex", "Environment"))

#Change names to make them more clear
predictions.variance <- predictions.variance %>% 
      mutate(Sex = replace(as.character(Sex), Sex == "B", "Both"),
         Sex = replace(Sex, Sex == "M", "Male"),
         Sex = replace(Sex, Sex == "F", "Female")) %>%
  mutate(Environment = replace(as.character(Environment), Environment == "Stressed", "Stressful"),
         Environment = replace(Environment, Environment == "Unstressed", "Benign"))

colnames(predictions.variance) <- c("Sex", "Environment", "Prediction", "SE", "CI.lb", "CI.ub", "n")

#And plot the results, first for the posterior results of the brms model then for the metafor predictions

var.plot.posterior <- post.variance %>% mutate(Sex = factor(Sex, levels = c("Male", "Both", "Female"))) %>% ggplot()+
  stat_density_ridges(aes(x=value, y = Environment, fill = Sex), alpha = 0.65, scale = 0.6, position = position_nudge(y = 0.15), height = 10, show.legend = F, quantile_lines = T, quantiles = 2)+
  geom_vline(xintercept = 0, linetype = 2, colour = "black") + 
  ylab("Environment\n")+
  xlab("\nPhenotypic Variance (lnCVR)")+
  scale_x_continuous(limits = c(-2.1, 1.2), breaks = c(-2, -1.5, -1, -0.5, 0, 0.5, 1))+
  scale_fill_manual(values = c("Male" = "#e41a1c", "Female" = "#377eb8", "Both" = "#4daf4a"))+
  scale_color_manual(values = c("Male" = "#e41a1c", "Female" = "#377eb8", "Both" = "#4daf4a"))+
  
  theme_bw()+
  
  theme(panel.spacing = unit(0.1, "lines"),
        text = element_text(size=16),
        panel.border= element_blank(),
        axis.line=element_line(), 
        panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        panel.grid.minor.x = element_blank(), 
        legend.text = element_text(size=16), 
        legend.title=element_text(size=16, 
                                  face = "bold"),
        axis.title.x = element_text(hjust = 0.5, size = 14),
        axis.title.y = element_text(size = 16, hjust = 0.35, margin = margin(r=-10)),
        axis.text.y = element_text(angle = 0),
        plot.title = element_text(size = 16))


both.var.plots <- var.plot.posterior +
  geom_errorbarh(data = predictions.variance %>% mutate(Sex = factor(Sex, levels = c("Male", "Both", "Female"))), 
                 aes(x = Prediction, xmin = predictions.variance$CI.lb, 
                     xmax = predictions.variance$CI.ub, y = Environment,
                     color = Sex), 
                 height = 0, position = pd, show.legend = F) +
  geom_point(data = predictions.variance %>% mutate(Sex = factor(Sex, levels = c("Male", "Both", "Female"))), 
             aes(x = Prediction, y = Environment, size=n, fill = Sex), 
             shape=21, color = "grey20", position = pd) +
  guides(fill = guide_legend(reverse=T, override.aes = list(size = 7.5)))+
  scale_size(guide = 'none')+  


  scale_y_discrete(expand=c(0.075,0))

# svg("figures/both.var.plots.svg", width=6, height=6)
# both.var.plots
# dev.off()
# 
# pdf("figures/both.var.plots.pdf",  width = 6, height = 6)
# both.var.plots
# dev.off()

both.var.plots
```
<br></br>
**Figure S4:** Phenotypic variation changes under sexual selection in stressful environments. For females under stressful conditions phenotypic variation decreases (narrows). While for males in stressful environments it increases. For outcomes that measured a mix of both males and females (pooled samples) in stressful environments phenotypic variation decreased slightly. The REML predictions are shown as circles with error bars and the Bayesian predictions as density ridges. Circle size is proportional to sample size.


**Table S14** The REML predictions in the plot above use the following dataframe.
```{r}
predictions.variance <- format(predictions.variance, digits = 2)
predictions.variance %>% pander()
```

____________________

###Hypothesis Tests For Phenotypic Variation Model

Like we did for Hedges g' we can also conduct hypothesis tests between categorical groups to inform us if there is a difference between two groups of interest (e.g. females in benign and females in stressful environments). Here we present Bayesian and REML hypothesis predictions. Positive values indivate the first term in the hypothesis is larger (which would be male for rows 1-2 or benign for rows 3-5).

**Table S15** Bayesian hypothesis tests between categorical groups for phenotypic variation (lnCVR)
```{r}
#Obtain hypothesis estimates
brms.hypothesis.var <- hypothesis(var.brms, c("0 = SexF",
                             "0 = SexF + SexF:EnvironmentStressed",
                             "0 = SexF:EnvironmentStressed + EnvironmentStressed",
                             "0 = EnvironmentStressed",
                             "0 = SexB:EnvironmentStressed + EnvironmentStressed"))
#Format into dataframe
brms.hypothesis.table.var <- 
  data.frame(brms.hypothesis.var[["hypothesis"]][["Hypothesis"]],
             brms.hypothesis.var[["hypothesis"]][["Estimate"]],
             brms.hypothesis.var[["hypothesis"]][["Est.Error"]],
             brms.hypothesis.var[["hypothesis"]][["CI.Lower"]],
             brms.hypothesis.var[["hypothesis"]][["CI.Upper"]],
             brms.hypothesis.var[["hypothesis"]][["Star"]])
colnames(brms.hypothesis.table.var) <- c("Hypothesis", "Estimate", "Est.Error", "CI.Lower", "CI.Upper", " ")
row.names(brms.hypothesis.table.var) <- c("M vs F, Benign", "M vs F, Stressful", "Benign vs Stressful, Female", "Benign vs Stressful, Male", "Benign vs Stressful, Both")
brms.hypothesis.table.var <- format(brms.hypothesis.table.var, digits = 2)
brms.hypothesis.table.var %>% pander(split.table = Inf)
```

**Table S16** REML hypothesis tests between categorical groups for phenotypic variation (lnCVR)
```{r}
#anova where you specify the values based on the list of moderators
anova.1 = anova(variance.model, L=c(0, 0, -1, 0, 0, 0)) 
anova.2 = anova(variance.model, L=c(0, 0, -1, 0, 0, -1))
anova.3 = anova(variance.model, L=c(0, 0, 0, -1, 0, -1))
anova.4 = anova(variance.model, L=c(0, 0, 0, -1, 0, 0))
anova.5 = anova(variance.model, L=c(0, 0, 0, -1, -1, 0))

anova.list.var <- list(anova.1, anova.2, anova.3, anova.4, anova.5)

anova.frame.var <- t(data.frame(lapply(anova.list.var, function(x) {
  data.frame(x[["hyp"]],
  x[["Lb"]],
  x[["se"]],
  x[["Lb"]] - 1.96*x[["se"]],
  x[["Lb"]] + 1.96*x[["se"]],
  x[["pval"]])
})))
anova.frame.var <- as.data.frame(split(anova.frame.var, rep(1:6)))
colnames(anova.frame.var) <- c("Hypothesis", "Estimate", "Est.Error", "CI.Lower", "CI.Upper", "pval")
anova.frame.var$Estimate <- as.numeric(levels(anova.frame.var$Estimate))[anova.frame.var$Estimate]
anova.frame.var$Est.Error <- as.numeric(levels(anova.frame.var$Est.Error))[anova.frame.var$Est.Error]
anova.frame.var$CI.Lower <- as.numeric(levels(anova.frame.var$CI.Lower))[anova.frame.var$CI.Lower]
anova.frame.var$CI.Upper <- as.numeric(levels(anova.frame.var$CI.Upper))[anova.frame.var$CI.Upper]
anova.frame.var$pval <- as.numeric(levels(anova.frame.var$pval))[anova.frame.var$pval]
anova.frame.var <- format(anova.frame.var, digits = 2)
anova.frame.var$star <- c("*", "*", "*", "*", "*")
colnames(anova.frame.var)[colnames(anova.frame.var)=="star"] <- " "
anova.frame.var$pval <- NULL
row.names(anova.frame.var) <- c("M vs F, Benign", "M vs F, Stressful", "Benign vs Stressful, Female", "Benign vs Stressful, Male", "Benign vs Stressful, Both")
anova.frame.var %>% pander(split.table = Inf)
```

____________________

###Estimating lnCVR Heterogeneity Using _I^2^_

Similar to the meta-analysis on Hedges' g we can obtain _I^2^_ for lnCVR REML model. In this case (compared to Hedges' g) we see Taxon has more of a variable effect on overall _I^2^_ estimates, although the overall _I^2^_ remains relatively similar (95.4 %). 

```{r}
I2(variance.model, restricted.data2$var.g) %>% pander(digits = 3)
```
_________

##Publication Bias

###Funnel plots and Egger's Test

Here we check for publication bias with a funnel plot. Note that the trim and fill or Eggers test method does not work with rma.mv objects. We can perform Eggers test using the ``regtest()`` function. This tests for asymmetry via assessing relationships between effect size and a specified predictor. Because the Eggers test does not work for ``rma.mv`` objects we remove the random effects and run with Sex * Environment as moderators. 
```{r}
standard.model <- rma(g, var.g, 
                      mods = ~ Sex * Environment, 
                      data=prelim.data)
regtest(standard.model)
```

We can use ggplot for creating a funnel plot. The outline taken from is taken from: https://sakaluk.wordpress.com/2016/02/16/7-make-it-pretty-plots-for-meta-analysis/

```{r, fig.height= 6, fig.width=8, warning=FALSE, message=FALSE}

#Using residuals for the funnel plot means that we need to generate residuals (intercept only)

forest.model <- rma.mv(g, var.g,
                       mods = ~ 1,
                       random = list(~ 1 | Study.ID,
                                       ~ 1 | Outcome),
                       method = "REML",
                       data = prelim.data)

# Obtain residuals
resstandards <- (rstandard.rma.mv(forest.model,
                                   type="response"))

# Obtain grand mean effect size 
grand.mean <- as.numeric(forest.model$b) 

# Create new df with residuals replacing raw
df.forest.model <- prelim.data
df.forest.model$g <- resstandards$resid + grand.mean 
df.forest.model$sei <- resstandards$se

# Funnel plot for all outcome classes

make.funnel <- function(dataset, model){
  
  apatheme <- theme_bw() +  #My APA-format theme
    theme(panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.border = element_blank(),
          axis.line = element_line(),
          text = element_text(family = 'Times'),
          legend.position = 'none')
  
  estimate <- model$b
  SE <- model$se
  se.seq <- seq(0, max(sqrt(dataset$var.g)), 0.001)
  dfCI <- data.frame(ll95 = estimate - (1.96 * se.seq), 
                     ul95 = estimate + (1.96 * se.seq), 
                     ll99 = estimate - (3.29 * se.seq), 
                     ul99 = estimate + (3.29 * se.seq), 
                     se.seq = se.seq, 
                     meanll95 = estimate - (1.96 * SE), 
                     meanul95 = estimate + (1.96 * SE))
  
  ggplot(dataset, aes(x = sqrt(var.g), y = g)) +
    geom_point(size=1.5, shape = 21, color= "grey20") +
    xlab("Standard Error") + ylab("Effect Size (Hedges' g)") +
    geom_line(aes(x = se.seq, y = ll95), linetype = 'dotted', data = dfCI) + # confidence lines
    geom_line(aes(x = se.seq, y = ul95), linetype = 'dotted', data = dfCI) +
    geom_line(aes(x = se.seq, y = ll99), linetype = 'dashed', data = dfCI) +
    geom_line(aes(x = se.seq, y = ul99), linetype = 'dashed', data = dfCI) +
    #Now plot dotted lines corresponding to the 95% CI of your meta-analytic estimate
    geom_segment(aes(x = min(se.seq), y = meanll95, xend = max(se.seq), yend = meanll95), linetype='dotdash', data=dfCI, colour = "tomato",size =0.75) +
    geom_segment(aes(x = min(se.seq), y = meanul95, xend = max(se.seq), yend = meanul95), linetype='dotdash', data=dfCI, colour = "tomato",size=0.75) +
    scale_x_reverse() +
    # scale_y_continuous(breaks = seq(-1.25,2,0.25)) + #Choose values that work for you based on your data
    coord_flip() +
    scale_fill_brewer(palette = "Set1")+

    theme_bw()+
  
    theme(panel.spacing = unit(0.5, "lines"),
        panel.border= element_blank(),
        text = element_text(size=14),
        axis.line=element_line(),
        panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        panel.grid.minor.x = element_blank(),
        legend.text = element_text(size=12),
        legend.title=element_text(size=12,
                                  face = "bold"),
        axis.title.x = element_text(hjust = 0.5, size = 12),
        axis.title.y = element_text(size = 12))

}

funnel.plot <- make.funnel(df.forest.model, forest.model)

ggsave(plot = funnel.plot, filename = "figures/funnel_plot.eps", height = 7.5, width = 10)
funnel.plot

# svg("figures/funnel_plot.svg", width=8, height=6)
# funnel.plot
# dev.off()
```
<br></br>
**Figure S5:** A funnel plot of 459 effect sizes shows asymmetry, indicating potential publication bias, egger's regression test for funnel plot asymmetry also suggests the plot is asymmetrical (z = 6.2210, p < .0001). The asymmetry appears to be sourced from a spread of positive effect sizes outside the funnel and of varying degrees of precision. Counter to expectations of publication bias these positive studies are not just 'low precision, large effect' results. Funnel plot asymmetry may also be due to heterogeneity, which in this study is high due to the many species and outcomes measured. 


###Journal Impact Factor

If we see a positive trend with effect size and Journal Impact Factor (JIF) it may represent publication bias whereby significant (positive) results are published more readily and in more circulated journals and non-confirmitory or negative results are not published or publiushed in lower impact journals. Our journal impact factor dataset is not evenly distributed as several publications in Nature (JIF ~ 40) are much larger than the next highest JIF (~11). 

```{r, fig.height= 4, fig.width=8, warning=FALSE}

JIF.plot <- ggplot(data = prelim.data, aes(x=JIF, y=g))+
  geom_jitter(color='darkgreen', alpha=0.4, aes(size = (1/(var.g))/sum((1/(var.g)))*100), show.legend = FALSE)+
  geom_hline(yintercept=0, linetype = 'dotted')+
  geom_smooth(method='lm', color='black', linetype="solid")+
  scale_x_log10(limits = c(-5,40), breaks = c(0, 1, 2, 5, 10, 20, 40))+
  labs(size = 'Weight (%)', y='Effect size (Hedges g)', x= 'Journal Impact Factor (logarithmic scale)')+ 
  
  theme_bw()+
  
    theme(panel.spacing = unit(0.5, "lines"),
        panel.border= element_blank(),
        text = element_text(size=14),
        axis.line=element_line(),
        panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        panel.grid.minor.x = element_blank(),
        legend.text = element_text(size=12),
        legend.title=element_text(size=12,
                                  face = "bold"),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_text(size = 12))

# dev.off()
# 
# svg("figures/JIF_Plot.svg", width=4, height=4)
# JIF.plot
# dev.off()

JIF.plot

```
<br></br>
**Figure S6:** Journal impact factor does not show a noticable correlation with effect size. The positive slope shown here is due to several effect sizes published in a high impact journal. Most papers were published in discipline specific journals such as _Evolution_ and _Journal of Evolutionary Biology_. Circle size is proportional to weight (%) of study. 

We can test the effect of JIF on ES with a simple linear model: 
```{r}
JIFlm <- lm(g ~ log(JIF), data = prelim.data)
summary(JIFlm)
```

This shows that JIF does not have a significant effect on effect sizes from the published study

### Time-lag Bias

We can also look at the time-lag bias, which suggests effect size decreases over time. Again, because one publication from 1980 is well before the next publication in the late 1990s we see a very uneven distribution of data points.

```{r, fig.height= 4, fig.width=8, warning=FALSE}
time.plot <- prelim.data %>% 
  ggplot(aes(x=Year, y=g))+
  geom_jitter(color='darkorange', alpha=.5, aes(size = (1/(var.g))/sum((1/(var.g)))*100), show.legend = FALSE)+
  geom_hline(yintercept=0, linetype = 'dotted')+
  geom_smooth(method='lm', color='black')+
  labs(size = 'Weight (%)', y='Effect size (Hedges g)', x= 'Year')+
    theme_bw()+
    theme(panel.spacing = unit(0.5, "lines"),
        panel.border= element_blank(),
        axis.line=element_line(),
        text = element_text(size=14),
        panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        panel.grid.minor.x = element_blank(),
        legend.text = element_text(size=12),
        legend.title=element_text(size=12,
                                  face = "bold"),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_text(size = 12))

time.plot

# svg("figures/Time_Plot.svg", width=4, height=4)
# time.plot
# dev.off()
```
<br></br>
**Figure S7:** The effect size dataset shows little to no signs of the time-lag bias as the average effect sizes from published studies remains consistent across the previous two decades. Circle size is proportional to weight of study (%).


We can also test the effect of publication year on ES with a simple linear model (similar to the one for JIF: 
```{r}
Yearlm <- lm(g ~ Year, data = prelim.data)
summary(Yearlm)
```

This shows that publication year does not have a significant effect on effect sizes from the published study.

________________

##Other Moderators

### Blinding

In addition to publication bias, other forms of bias may exist within studies. We initially collected data on whether studies were blind or not. Although not many studies (n=8) used blinding there was multiple effect sizes reported in these studies, thus we can visualise whether blinding affects the effect sizes from the model. Blinding was regarded as a redundant predictor in the model (estimate = 0.0287, p = 0.8974) and was dropped. 

```{r, fig.height= 6, fig.width=8}
blind.plot <- df.forest.model %>% ggplot(aes(x=Blinding, y=g))+
  geom_boxplot(outlier.shape = NA)+
  geom_jitter(aes(fill=Blinding, size = (1/(var.g))/sum((1/(var.g)))*100), shape=21, color='grey20')+
  geom_hline(yintercept=0, linetype = 'dotted') + 
  scale_fill_brewer(palette = "Set2")+
  labs(y="Effect size (Hedges' g)", x= 'Blinding', size = 'Weight (%)')+
  guides(fill=FALSE, size = guide_legend(override.aes = list(fill = "#66c2a5")))+
  theme_bw()+
  theme(panel.spacing = unit(0.5, "lines"),
        panel.border= element_blank(),
        axis.line=element_line(),
        text = element_text(size=14),
        panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        panel.grid.minor.x = element_blank(),
        legend.text = element_text(size=12),
        legend.title=element_text(size=12,
                                  face = "bold"),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_text(size = 12))

#ggsave(plot = blind.plot, filename = "figures/blind_plot.eps", height = 6, width = 8)
blind.plot
```
<br></br>
**Figure S9:** Blinding does not appear to alter the magnitude or direction of effect sizes for the studies used in this meta-analysis. However, this should not be viewed as evidence against the validity of blinding as a research method. 

____________

### Generations

We recorded the number of generations of experimental exolution each study used. The number of generations proved a negligible predictor in the meta-analytic models (estimate = 0.0019, p = 0.2341). The effect sizes are plotted against the generation at which the effect size was extracted. 

```{r, fig.height= 6, fig.width=8, warning=FALSE}
generations.plot <- restricted.data %>% ggplot(aes(x=Generations, y=g))+
  geom_jitter(shape=21, color = "grey20", size=2, aes(fill=Taxon))+
  ylim(-3.5,3.5)+
  geom_hline(yintercept=0, linetype="dashed") + 
  scale_fill_brewer(palette = "Set3")+
  geom_smooth(method = 'lm', color='black')+
  labs(y="Effect size (Hedges' g)", x= 'Generations', size= 'Weight (%)')+
  theme_bw()+
  theme(panel.spacing = unit(0.5, "lines"),
        panel.border= element_blank(),
        axis.line=element_line(),
        text = element_text(size=14),
        panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        panel.grid.minor.x = element_blank(),
        legend.text = element_text(size=12),
        legend.title=element_text(size=12,
                                  face = "bold"),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_text(size = 12))

#ggsave(plot = generations.plot, filename = "figures/generations_plot.eps", height = 7.5, width = 10)

# svg("figures/Generations_Plot.svg", width=10, height=7.5)
# generations.plot
# dev.off()

generations.plot
```
<br></br>
**Figure S10:** The number of generations an experimental evolution procedure is run for does not appear to affect the magnitude or direction of the effect size from the fitness related outcome measured at that point. 
<br></br>
A linear model shows next to no effect of generations on effect size: 
```{r}
summary(lm(g ~ Generations, data = restricted.data))
```

@Kawecki_2012 reviewed the field of experimental evolution and noted that changes to variation may need longer generations to become apparent. The following graph looks at the relationship between number of generations and lnCVr:

```{r, fig.height= 7.5, fig.width=10, warning=FALSE}
generations.plot.var <- restricted.data2 %>% ggplot(aes(x=Generations, y=lnCVr))+
  geom_jitter(shape=21, color = "grey20", size=2, aes(fill=Taxon))+
  ylim(-3.5,3.5)+
  geom_hline(yintercept=0, linetype="dashed") + 
  scale_fill_brewer(palette = "Set3")+
  geom_smooth(method = 'lm', color='black')+
  labs(y='Effect size (lnCVR)', x= 'Generations', size= 'Weight (%)')+
  theme_bw()+
  theme(panel.spacing = unit(0.5, "lines"),
        panel.border= element_blank(),
        text = element_text(size=14),
        axis.line=element_line(),
        panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        panel.grid.minor.x = element_blank(),
        legend.text = element_text(size=12),
        legend.title=element_text(size=12,
                                  face = "bold"),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_text(size = 12))

# ggsave(plot = generations.plot, filename = "figures/generations_plot.eps", height = 7.5, width = 10)
generations.plot.var
```

**Figure S11:** Phenotypic variation (lnCVR) is not affected by the number of generations an experiment is ran for.

```{r}
summary(lm(lnCVr ~ Generations, data = restricted.data2))
```


________________

##R Session Information

This section shows the operating system and R packages attached during the production of this document

```{r}
sessionInfo() %>% pander
```


________________

##References
 <br/><br/> 
<!-- Some JavaScript to control the buttons to show/hide the big tables -->
<script>
$( "input.hideshow" ).each( function ( index, button ) {
  button.value = 'Hide Output';
  $( button ).click( function () {
    var target = this.nextSibling ? this : this.parentNode;
     target = target.nextSibling.nextSibling.nextSibling.nextSibling.nextSibling;
    if ( target.style.display == 'block' || target.style.display == '' ) {
      target.style.display = 'none';
      this.value = 'Show Output';
    } else {
      target.style.display = 'block';
      this.value = 'Hide Output';
    }
  } );
} );
</script>