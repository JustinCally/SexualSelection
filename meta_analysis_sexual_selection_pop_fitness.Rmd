---
title: 'Effects of sexual selection on non-sexual fitness components: a meta-analysis'
author: "Justin G. Cally^1^, Luke Holman^1^, Devi Stuart-Fox^1^ <br></br> <br></br> ^1^The University of Melbourne"
subtitle: Supplementary Material
output:
  html_document:
    toc: true # table of content true
    toc_float: true # make 
    depth: 3  # upto three depths of headings (specified by #, ## and ###)
    number_sections: false  ## if you want number sections at each table header
    theme: yeti # lovely fonts and colours
    code_folding: hide # awesome buttons to show/hide the code
  pdf_document: default
---

```{r warning=FALSE, message=FALSE, results='hide'}
library(knitr)
library(pander)
library(compute.es)
library(metafor)
library(dplyr)
library(lme4)
library(forestplot)
library(ggplot2)
library(kableExtra)
library(ggrepel)
library(reshape2)
library(RColorBrewer)
source("Vdodge_function.R") # nice function for ggplot
```

```{r echo=FALSE, results='hide'}
library(knitr) # set up cacheing to save time when re-building the html document
```
`r opts_chunk$set(cache=TRUE)`

## Supplementary Methods

Our aim was to investigate the effects of sexual selection on population fitness by conducting a meta-analysis on studies that measured fitness related outcomes after experimentally evolving a population under varying levels of opportunity for sexual selection. Here we describe the process of the literature search, data extraction, effect size calculation, formulation of multilevel models and assessing publication bias.

### Literature Search

**The literature search was conducted under the following conditions:**

1. We searched ISI Web of Science and Scopus on 9th June 2017. The two search engines produded a somewhat different set of papers (**PRISMA Figure**).

2. Studies were restricted to those from peer-reviewed and in the English language.

3. We devised a search strategy that sought to find studies which manipulated the presence or strength of sexual selection using experimental evolution, and then measured some proxy of population fitness. As such the search terms were as follows: 

<br></br>

**_ISI Web of Science_**

We used the following search on ISI Web of Science:

Topic (TS) = “Sexual Selection” OR Promisc* OR Monogam* OR Polygam* OR Polyandr* OR Polygyn* OR “Mate choice”

AND

Topic (TS) = Fitness OR “Population Fitness” OR Deleterious OR “Male Strength” OR Fecund* OR Viability OR Productiv* OR “Reproductive Success” OR “Reproductive Rate” OR Surviv* OR | “Development Rate” OR Extinct* OR “Competitive Success” OR Mortality OR Mass OR “Body Size” OR “Wing Size” OR Emergence OR Mating Rate OR “Mating Propensity” OR Adapt* OR “Novel | Environment” OR “Sexual Conflict” OR “Sexual Antagonis*”

AND

Topic (TS) = Generations OR “Experimental evolution” OR “mutation load”

AND

Research Area (SU) = “Evolutionary Biology”

<br></br>

**_Scopus_**

We used the following search on Scopus:

TITLE-ABS-KEY = “Sexual Selection” OR Promisc* OR Monogam* OR Polygam* OR Polyandr* OR Polygyn* OR “Mate choice”

AND

TITLE-ABS-KEY = Fitness OR “Population Fitness” OR Deleterious OR “Male Strength” OR Fecund* OR Viability OR Productiv* OR “Reproductive Success” OR “Reproductive Rate” OR Surviv* | OR “Development Rate” OR Extinct* OR “Competitive Success” OR Mortality OR Mass OR “Body Size” OR “Wing Size” OR Emergence OR Mating Rate OR “Mating Propensity” OR Adapt* OR | “Novel Environment” OR “Sexual Conflict” OR “Sexual Antagonis*”

AND

TITLE-ABS-KEY = Generations OR “Experimental evolution” OR “mutation load”

### Additions to the Literature Search

In addition to studies found from the literature search we also included three relevant studies that we found, which were not picked up in the subsequent formal searches (Partridge 1980; Price et al. 2010; Savic Veselinovic et al. 2013; **PRISMA Figure**). 

### Data extraction

After removing duplicates papers recovered from both ISI and Scopus, we read the titles and abstracts of the remaining 1015 papers, and removed papers that were not relevant (typically because they were not an empirical study using experimental evolution). This left 130 papers, for which we read the full text and applied the following selection criteria: 

  + **(1: Study Design)** The study was an experimental evolution study lasting >1 generation
  + **(1: Population)** a) The study was conducted using an animal species that was b) diecious
  + **(1: Intervention and Control)** The study experimentally manipulated the strength of sexual selection (e.g. via enforced monogamy or an altered sex ratio)
  + **(1: Outcomes)** The study measured a trait that we judged to be a potential correlate of population fitness. 
  
This latter criterion is likely to be contentious, because there is rarely enough data justify the assumption that a particular trait is (or is not) correlated with population fitness. We therefore relied on our best judgement when deciding which studies to exclude (see **Table S1**). The inclusion/exlusion critera as applied to each study are detailed in **Table S2**.

**Table S1:** We classed each of the twenty fitness related outcomes into three broad groups of direct, indirect and ambiguous based on the established link with population fitness, the directionality of the measure. Here we detailed how these outcomes were measured in the studies of this meta-analysis. In the accompanying box we provide a legend to the references cited in the table.

 <br/><br/>
```{r, warning=FALSE}
outcome.descriptions <- read.csv('data/outcome.descriptions.csv', 
                                 fileEncoding="UTF-8")
kable(outcome.descriptions, "html") %>%
  kable_styling() %>%
  scroll_box(width = "800px", height = "500px")
```
  <br/><br/> 
<input type=button class=hideshow></input>
```{r, warning=FALSE}
outcome.references <- read.csv('data/references.tableS1.csv', 
                                 fileEncoding="UTF-8")
kable(outcome.references, "html") %>%
  kable_styling() %>%
  scroll_box(width = "800px", height = "250px")
```
  <br/><br/> 

**Table S2:** An eligibility criteria was based on four features a study needed to include (discussed above), to be eligable for inclusion in the meta-analysis the study needed to satisfy all criteria. Here we applied a step-wise process to the studies that had their full-text read and excluded them when they first failed to meet the criteria. Additional notes documenting reasons behind exclusion were also taken.
 <br/><br/> 
<input type=button class=hideshow></input>
```{r}
Eligibility.criteria <- read.csv('data/Eligibility Workbook(22.02).csv', 
                                 fileEncoding="UTF-8")
kable(Eligibility.criteria, "html") %>%
  kable_styling() %>%
  scroll_box(width = "800px", height = "500px")
```



### Effect Size Calculation

A spreadsheet describing the data that was extracted from each of the included studies is included as supplementary material. It details the type of data collected for each study (arithmatic means, SD, n, F-statistic, chi-squared, proportion etc.). The rules utilised were as follows: 

1. Arithmatic means, standard deviations/errors and sample sizes were extracted from a paper, supplementary material or a linked data repository (e.g. Data Dryad). This was possible when means and SD were reported in text or in a table. We would preferentially extract data for each experimental evolution line/replicat/family if possible and only extract data for the final reported generation (which was noted down).

2. If we could not find the means and SD in text format we used web-plot digitizer (v.3.12) to extract data from graphs. 

3. If means were not reported then we extracted a summary statistic or proportion value, which we could later convert to Hedges g' using the _compute.es_ package. Summary statistics included _F_, _z_, _t_ and _chi^2^_. These conversions still required providing sample sizes for each treatment so these needed to be extractable from the study. Some summary statistics were obtained from generalized linear model summary tabels, others from straight forward ANOVAs and then some from more complex analysis such as proportional hazards statistical tests. 

4. We also collected various covariates for some of the studies (**Table S3**), which are discussed later.

______________

## The Effect Size Dataset

### Table of Effect Sizes

>Justin Says: I think I need to clean up some of the notes and make them more readable

**Table S3:** Table of effect sizes included in our meta-analysis. See the text following the table for an explanation of each column.
 <br/><br/> 
<input type=button class=hideshow></input>
```{r}
# Load the data and clean up the variable formats
prelim.data <- read.csv('data/Preliminary data frame 22.2.18.csv')
prelim.data$Study.ID <- prelim.data$Study.ID %>% factor()
prelim.data$Taxon <- prelim.data$Taxon %>% factor()
prelim.data$Group.ID <- prelim.data$Group.ID %>% factor()
prelim.data$Authors <- prelim.data$Authors %>% factor()
prelim.data$Environment <- prelim.data$Environment %>% factor %>% relevel(ref="Unstressed")
prelim.data$Sex <- prelim.data$Sex %>% factor %>% relevel(ref="B")
prelim.data$Ambiguous <- prelim.data$Ambiguous %>% factor()
prelim.data$Species <- prelim.data$Species %>% factor()
#Outcome.Class.2 is using the categories that were decided by survey. I am keeping both just to check them against each other (how much of a difference it makes)
prelim.data$Outcome.Class <- prelim.data$Outcome.Class %>% factor() %>% relevel(ref="Indirect")
prelim.data$Enforced.Monogamy <- prelim.data$Enforced.Monogamy %>% factor() %>% relevel(ref="NO")
prelim.data$Pre.cop <- prelim.data$Pre.cop %>% factor() %>% relevel(ref="0")
prelim.data$Post.cop <- prelim.data$Post.cop %>% factor() %>% relevel(ref="0")
prelim.data$Blinding <- prelim.data$Blinding %>% factor()

kable(prelim.data, "html") %>%
  kable_styling() %>%
  scroll_box(width = "800px", height = "500px")
```
<br></br>

**Study ID**: An ID given to the published paper the effect size is sourced from (n=65).

**Group ID**: An ID given to the research group that may have published several papers on the same species usuing the same or very similar experimental setup. [Was not use in analysis]

**Species**: The species used in the experimental evolution procedure (n = 15).

**Taxon**: The taxon to which the species belongs. One of the following: Beetle, fly, mouse, nematode, guppy, mite and cricket (taxa were selected arbitrarily based on the available data). 

**SS Strength, Ratios and SS Density's (Column 7-9)**: Various ratios of the number of males to females and the total number of individuals kept together in an experiment [Was not used in any analysis]

**Post cop and Pre cop**: Whether a study allowed Pre/Post-copulatory sexual selection (1) or not (0).

**Blinding**: A binary classification, describing whether blind protocols were used during the experiment. Papers were assumed to be not blind unless declared otherwise.

**Generations**: The number of generations that the species was subject to differing levels of sexual selection, ranging from 1 to 162. 

**Enforced Monogamy**: Whether the study had the low sexual selection treatment as enforced monogamy (YES) or not (NO). Not all studies compared enforced monogamy and SS+ treatments. Some used FB vs MB, where FB is the SS (low intensity). 

**n**: Pooled sample size of the paired treatments.

**Outcome**: The fitness related outcome that was measured, e.g. fecundity, survival, or mating success (see Table S1 for all 20 categories). We applied our own classifications rather than relying on those provided by the authors, because different papers sometimes used different names for the same trait. 

**Outcome Class**: To help guide analysis the outcomes were classed into three categories; ambiguous, indirect and direct (see Table S1).

**Sex**: A moderator variable with three levels, describing whether the effect size in question comes from a measurement of males (M), females (F), or individuals of both sexes (B).

**Ambiguous**: Is the fitness outcome ambiguous (YES) or not ambigous (NO). Ambiguous outcomes may be those that may not necessarily be directional, that is to say they may be a life history trait. 

**Environment**: In the methods of the papers included in this study it was usually stated whether additional modifications to the experimental lines were made. Briefly, this was usually a modification that made conditions more stressful such as using a novel food source or elevated mutation load, the effect sizes from these experimental lines are labelled as 'Stressed'. If it was clearly stated that there was no such modification it is labelled 'Unstressed'. However, sometimes the paper was ambiguous in what lines had added stress or the results from stressed and unstressed lines were pooled together, in this case we label it as 'Not Stated'.

**g**: Hedge's g calculated using the compute.es package.

**var.g**: The within study variance associated with the effect size, g.

**Positive Fitness**: Whether the measurment used in the study is beneficial for fitness (1) or not (0). Note that g has already been multiplied by this column. 

**mean/sd/n.low/high**: The means, standard deviation and sample size for the low or high sexual selection treatments, used to calculate lnCVR (meta-analysis of variance). Rows without these values had hedges g' derived from summary statistics (F, z, chi-square etc.).

**JIF**: Journal Impact factor at year of publication. Several impact factors were unable to be determined/found and are NA.We obtained the journal impact factor for each effect size at the time of publication using InCites Journal Citation Reports.
<br></br>

### Table of sample sizes

The number of effect sizes, publications, blind experiments, effect sizes in stressed conditions, male, female and both measures and different species used, with the number of effect sizes per taxon also reported. 

**Table S4:** Table of effect sizes included in our meta-analysis. See the text following the data table for an explanation of each column.
 <br/><br/> 
<input type=button class=hideshow></input>
```{r message=FALSE, warning=FALSE}
n.blind.ones <- (sum(prelim.data$Blind == "Blind"))
prelim.data %>% 
  summarise(
    Effect_sizes_.Totalq = n(), 
    Publications = prelim.data$Study.ID %>% unique() %>% length(),
    Blind_experiments = n.blind.ones,
    Effect_sizes_.Stressedq = (sum(prelim.data$Environment == "Stressed")),
    Effect_sizes_.Unstressedq = (sum(prelim.data$Environment == "Unstressed")),         
    Effect_sizes_.Maleq = (sum(prelim.data$Sex == "M")),
    Effect_sizes_.Femaleq = (sum(prelim.data$Sex == "F")),
    Effect_sizes_.Both_sexesq = (sum(prelim.data$Sex == "B")),
    Different_species =  prelim.data$Species %>% unique() %>% length(),
    Effect_sizes_.Beetleq = sum(Taxon == "Beetle"),
    Effect_sizes_.Flyq = sum(Taxon == "Fly"),
    Effect_sizes_.Mouseq = sum(Taxon == "Mouse"),
    Effect_sizes_.Nematodeq = sum(Taxon == "Nematode"),
    Effect_sizes_.Miteq = sum(Taxon == "Mite"),
    Effect_sizes_.Cricketq = sum(Taxon == "Cricket"),
    Effect_sizes_.Guppyq = sum(Taxon == "Guppy")) %>% melt() %>%
  mutate(variable = gsub("_", " ", variable),
         variable = gsub("[.]", "(", variable),
         variable = gsub("q", ")", variable)) %>% 
  rename_("n" = "value", " " = "variable") %>% 
  pander(split.cell = 40, split.table = Inf)
```
 <br/><br/> 
**Table S5:** Table of fitness outcomes included in our meta-analysis by sex.
 <br/><br/> 
<input type=button class=hideshow></input>
```{r}
Outcome_and_sex <- as.data.frame.matrix(table(prelim.data$Outcome, prelim.data$Sex))
colnames(Outcome_and_sex) <- cbind("Both", "Female", "Male")

Outcome_and_sex %>% pander(split.cell = 40, split.table = Inf)

```
<br></br>

### Forest plot

Here we show the residual effect sizes for each outcome measured. The following forest plot is based on the residual effect sizes. The model is an intercept only model with standard random effects structure.

> Although I am not sure whether having the raw values would be better. In addition whether it is worth it to add in summary polygons (effect sizes) for a grouped outcome

> Luke says: if you are plotting RESIDUAL effect sizes, doesn't that mean this plots shows each effect size, relative to the grand mean effect size? Like, -0.05 means it is below average, but the effect is still positive since the grand mean is +0.1. This is probably not what we want. 

> I have modified the code below so that it plots the resid + the grand mean. But I think since model is intercept only, this might be the same thing as the raw data... not sure. Have a think, or just plot all the raw effect sizes +/- their 95% CIs, instead of the residuals.

> Also try to make it clear what positive g means (I guess positive g means higher fitness when SS is present/strong?)


```{r, fig.height=25, fig.width=10}
# Run standard random effects model
# forest.model <- rma.mv(g, var.g, 
#                        mods = ~ 1 + Sex * Environment + Taxon,
#                        random = list(~ 1 | Study.ID, 
#                                        ~ 1 | Outcome),
#                        method = "REML", 
#                        data = prelim.data)
# 
# # Obtain residuals
# resstandards <- (rstandard.rma.mv(forest.model, 
#                                    type="response"))
# 
# # Obtain grand mean effect size    <- ADDED BY LUKE
# grand.mean <- as.numeric(forest.model$b)
# 
# # Create new df with residuals replacing raw
# df.forest.model <- prelim.data                     # <- Luke says: you could just use prelim.data itself, not the residuals?
# df.forest.model$g <- resstandards$resid + grand.mean   # <- ADDED BY LUKE
# df.forest.model$sei <- resstandards$se

# Create new factor to order factors in a way where Ambig, Indirect and Direct are Grouped
prelim.data$Outcome_f = factor(prelim.data$Outcome, levels = c('Behavioural Plasticity', 'Body Size', 'Development Rate', 'Early Fecundity', 'Immunity', 'Mating Duration', 'Pesticide Resistance', 'Mutant Frequency', 'Body Condition', 'Fitness Senescence', 'Lifespan', 'Male Attractiveness', 'Mating Frequency', 'Mating Latency', 'Mating Success', 'Strength', 'Ejaculate Quality and Production', 'Extinction Rate', 'Offspring Viability', 'Reproductive Success'))

# define upper and lower bounds
prelim.data$lowerci <- prelim.data$g - 1.96*(sqrt(prelim.data$var.g))
prelim.data$upperci <- prelim.data$g + 1.96*(sqrt(prelim.data$var.g))

# Get author and year in one
short.author.names <- data.frame(long = prelim.data$Authors %>% unique(),
                                 short = prelim.data$Authors %>% unique() %>% 
  as.character() %>% 
  strsplit(split = ",") %>% 
  sapply(FUN=function(x) x[1])) %>%
  left_join(prelim.data %>% select(Authors, Year) %>% distinct(), by = c("long" = "Authors")) %>%
  mutate(suffix = "")

# Sometimes there are multiple papers with the same first author from teh same year. Name these 2010a, 2010b etc
dups <- with(short.author.names, table(short, Year)) %>% melt()
dups <- dups[dups$value > 1, ]
for(i in 1:nrow(dups)){
  short.author.names$suffix[
    short.author.names$short == dups$short[i] &
      short.author.names$Year == dups$Year[i]] <- letters[1:dups$value[i]]
}

# Add the AuthorYear column to the dataframe of effect sizes
short.author.names <- short.author.names %>%
  mutate(AuthorYear = paste(short, " ", Year, suffix, sep="")) %>%
  select(long, AuthorYear)
prelim.data <- prelim.data %>% 
  left_join(short.author.names, by = c("Authors" = "long")) 

#Generate a plot
p.meta <- prelim.data %>% 
  mutate(Sex = replace(as.character(Sex), Sex == "B", "Both"),
         Sex = replace(Sex, Sex == "M", "Male"),
         Sex = replace(Sex, Sex == "F", "Female")) %>%
  ggplot(aes(y=reorder(AuthorYear, -g), x = g, shape = Sex, color = Outcome.Class)) +
  geom_errorbarh(aes(xmin = lowerci, 
                     xmax = upperci), height = 0.1) +
  geom_point(size = 1.5) +
  scale_x_continuous(limits=c(-5, 5), name='Standardized Mean Difference (g) \n[positive values indicate sexual selection improves fitness components]') +
  scale_color_discrete(name = "Relationship\nto fitness") + 
  ylab('Reference') + 
  geom_vline(xintercept=0, color='black', linetype='dashed')+
  facet_grid(Outcome_f~., scales= 'free', space='free')+
  theme(strip.text.y = element_text(angle = 0))
ggsave(plot = p.meta, filename = "figures/Big_forest_plot.eps", height = 25, width = 12)
p.meta
```
<br></br>
**Figure S1:** Forest plot of raw effect sizes and their 95% confidence intervals, grouped according to environment (stressed or unstressed) and the sex of the individuals whose fitness trait was measured (male, female, or both sexes mixed together). Rows with multiple data points denote studies that provided multiple effect sizes. Positive values indicate fitness benefits of sexual selection. 

###Quantitative summary using bootstrapped means

We can obtain a bootstrap weighted mean for the entire dataset. Although this does not take into account any moderator variables it does provide a rough guide on where most of the datapoints sit: 

```{r}
#Run function
get.CIs.for.weighted.mean <- function(x, weights){
  total.resamples <- 10000
  num.chunks <- ceiling(length(x)*total.resamples / 10^7) # To be nice to RAM, let's keep these to ten million or less 
  if(num.chunks == 1){
    rand <- sample(length(x), length(x)*total.resamples, replace = TRUE)
    resampled.weighted.means <- data.frame(x = x[rand], w = weights[rand], replicate = rep(1:total.resamples, each = length(x))) %>% 
      group_by(replicate) %>% 
      summarise(w.mean = weighted.mean(x, w)) %>% .$w.mean
  }
  
  else{
    resampled.weighted.means <- vector(mode = "list", length = 0)
    number.of.resamples <- floor(total.resamples/num.chunks)
    final.chunk.size <- total.resamples - number.of.resamples * (num.chunks-1)
    for(i in 1:num.chunks){
      if(i == num.chunks) number.of.resamples <- final.chunk.size
      rand <- sample(length(x), length(x) * number.of.resamples, replace = TRUE)
      resampled.weighted.means[[i]] <- data.frame(x = x[rand], w = weights[rand], replicate = rep(1:number.of.resamples, each = length(x))) %>% 
        group_by(replicate) %>% 
        summarise(w.mean = weighted.mean(x, w)) %>% .$w.mean
    }
    resampled.weighted.means <- unlist(resampled.weighted.means)
  }
  
  data.frame(w.mean = median(resampled.weighted.means),
             lowerCI = quantile(resampled.weighted.means, probs = 0.025) %>% as.numeric(),
             upperCI = quantile(resampled.weighted.means, probs = 0.975) %>% as.numeric())
}

#Get weights
prelim.data$Standard.weights <- (1/prelim.data$var.g)

#Run function with weights
get.CIs.for.weighted.mean(prelim.data$g, prelim.data$Standard.weights) %>% pander()
```

>Could this be used as a line in the forest plot showing the average (or as a polygon at the bottom), or done for each outcome?

___________________

## Multilevel Meta-Analysis

> Let's just run one big model then cull from there

<!-- >The following documents how I could run individual models for each outcome or outcome.class of interest and then plot them. This may be good to add to the above forest plot (in the form of a polygon; how many studies report their estimates) but at the same time, it just adds results from different subsetted models rather than one combined one (as we use when investigating sex and environment) -->

<!-- > Nice idea, but I think the correct way to do this is to fit Outcome.class as a moderator, and then use predict() to find the average effect size within each of the 3 levels, as you have done below. I coded something below, but it's wrong: -->

<!-- ```{r} -->
<!-- model.outcome.class <- rma(g, var.g, -->
<!--                            mods = ~ Outcome.Class,  -->
<!--                            method = "REML",  -->
<!--                            intercept = TRUE,  -->
<!--                            data = prelim.data) -->

<!-- # Get the intercept (i.e. the grand mean for 'ambiguous', and the effects for the others) -->
<!-- mod.table <- do.call("cbind", model.outcome.class[names(model.outcome.class) %in% c("b", "ci.lb", "ci.ub")]) -->

<!-- data.frame(Outcome.class = c("Ambiguous", "Direct", "Indirect"), -->
<!--            mod.table) %>% -->
<!--   ggplot(aes(y = Outcome.class, x = V1))  + -->
<!--   geom_vline(xintercept = 0, linetype = 2) + -->
<!--   geom_errorbarh(aes(xmin = ci.lb, xmax = ci.ub), height=0) + -->
<!--   geom_point() +  -->
<!--   xlab("Effect size and 95% CIs") -->
<!-- ``` -->


<!-- There is not really enough direct outcomes to analyse by itself so hence we combine with indirect later -->
<!-- ```{r} -->
<!-- #Ambiguous outcomes -->

<!-- model.Ambiguous <- rma(g, var.g, -->
<!--                        mods = ~ 1,  -->
<!--                        method = "REML",  -->
<!--                        subset = (Outcome.Class == "Ambiguous"),  -->
<!--                        intercept = TRUE,  -->
<!--                        data = prelim.data) -->

<!-- summary(model.Ambiguous) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- #Indirect outcomes -->

<!-- model.Indirect <- rma(g, var.g, mods = ~ 1, method = "REML", subset = (Outcome.Class == "Indirect"), intercept = T ,data = prelim.data) -->

<!-- summary(model.Indirect) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- #Direct outcomes -->

<!-- model.Direct <- rma(g, var.g, mods = ~ 1, method = "REML", subset = (Outcome.Class == "Direct"), data = prelim.data) -->

<!-- summary(model.Direct) -->
<!-- ``` -->

<!-- Now let's combine into a data frame and plot. The following plot could then be added to the large forest plot as summary polygons or summary points with error bars.  -->

<!-- ```{r} -->
<!-- #Data frame -->
<!-- Outcome.category <- c('Ambiguous', 'Indirect', 'Direct') -->
<!-- Estimate <- c(model.Ambiguous$b, model.Indirect$b, model.Direct$b) -->
<!-- l.ci <- c(model.Ambiguous$ci.lb, model.Indirect$ci.lb, model.Direct$ci.lb) -->
<!-- u.ci <- c(model.Ambiguous$ci.ub, model.Indirect$ci.ub, model.Direct$ci.ub) -->
<!-- data.1 <- data.frame(Outcome.category, Estimate, l.ci, u.ci) -->

<!-- #plot -->

<!-- data.1 %>% ggplot(aes(x = Estimate, y= Outcome.category)) +  -->
<!--   geom_point() + -->
<!--   geom_vline(xintercept = 0, linetype = 2, colour = "grey70") +  -->
<!--   geom_errorbarh(aes(xmin = l.ci, xmax = u.ci), height = 0, size=1) + -->
<!--   ylab("Outcome Category")+ -->
<!--   xlab("Effect Size")+ -->
<!--   xlim(-.2, .5)+ -->
<!--   ggtitle('Meta-Analysis Results') -->
<!-- ``` -->

<!-- From the previous forest plot and models we see that overall sexual selection is beneficial towards population fitness. Although this is heavily modulated by the individual outcome and the outcome class. We explore heterogeneity in more depth later in this document.  -->

### Models With Many Covariates

We collected data from fitness components that were deemed ambiguous as well as unambiguous. The ambiguous outcomes are likely to add in heterogeneity to the models and not help us in answering questions of fitness effects of sexual selection. A model utilising our complete dataset with many moderator variables would thus be: 

```{r}
model.preliminary <- rma.mv(g, var.g, 
                         mods = ~ 1 + Sex * Environment + Taxon + Outcome.Class + Generations + Blinding, # << ----- Add big model, then cull predictors to this one
                         random = list(~ 1 | Study.ID, 
                                       ~ 1 | Outcome), 
                         method = "REML", 
                         data = prelim.data)

summary(model.preliminary)
```
<br></br>
**A note on random effects** Here we utilise crossed random effects of Study.ID and Outcome. Nesting Outcomes within Study.ID can also be achieved through ``random = ~ 1 | Study.ID/Outcome``. However given that the same outcome is expected to be measured in the same/very similar way between studies we used a crossed random effects design. 

From this model we can see that there are several redundant moderators: Blinding, Generations and the Outcome class (direct, indirect and ambiguous) show little effect and are not key to our research question (like sex and environment are). However, because taxa is a likely source of heterogeneity and effect size could reasonably be expected to differ between taxa, we investigate this fixed effect further...

__________________________________

### Sexual Selection Amongst Taxa

First we want to run the model using a restricted dataset where we remove effect sizes with Ambiguous outcomes (directionless or variable in their relation to fitness) or environments that were not stated whether they were stressed or unstressed (confusing and confounding). In this model we use Sex, Environment, Taxon and the interaction between sex and environment as we hypothesise that the a stressful enviornment may be of greater importance to the female sex due to 'female demographic dominance', which essentially states that female fitness is more important to the overall population demographics and that most benefits or conversely costs will accrue to female fitness components. 

```{r, warning=FALSE}
#Restrict the dataset for unambiguous outcomes and environments 
restricted.data <- prelim.data %>% 
  filter(Outcome.Class != "Ambiguous" & Environment != "Not Stated") %>% 
  mutate(Sex = as.character(Sex), 
         Environment = as.character(Environment), 
         Outcome.Class.2 = as.character(Outcome.Class), 
         Enforced.Monogamy = as.character(Enforced.Monogamy))

# Make sure the factors are leveled in the same order as we write our prediction function (below)
restricted.data$Environment <- restricted.data$Environment %>% factor() %>% relevel(ref="Unstressed")
restricted.data$Sex <- restricted.data$Sex %>% factor() %>% relevel(ref="M")
restricted.data$Outcome.Class <- restricted.data$Outcome.Class %>% factor() %>% relevel(ref="Indirect")
restricted.data$Taxon <- relevel(restricted.data$Taxon, ref = "Beetle") 

model.complete <- rma.mv(g, var.g, 
                         mods = ~ 1 + Sex * Environment + Taxon, # << ----- Add big model, then cull predictors to this one
                         random = list(~ 1 | Study.ID, 
                                       ~ 1 | Outcome), 
                         method = "REML", 
                         data = restricted.data)

summary(model.complete) 
```

The result is a model with estimates for various taxa, species, sexes and environments. To make sense of these estimates we should obtain average predictions for each moderator variable class of interest. We can do that by using a modified version version of a function used by Holman 2017. Here it alows us to cluster predictions for the different moderators of interest: Sex, environment, taxon etc. This is done by obtaining predictions using the base ``predict()`` function for the ``rma.mv()`` objects that have been previously created
```{r}
# function that makes predict.rma work like a normal predict() function, instead of the idiosyncratic way that it works by default.
get.predictions.complete <- function(newdata){
  B<-0; F<-0; Stressed<-0; Cricket<-0; Fly<-0; Guppy<-0; Mite<-0; Mouse<-0; interaction1<-0; interaction2<-0; interaction3<-0
  if(newdata[1] == "B") B<-1 
  if(newdata[1] == "F") F<-1 
  if(newdata[2] == "Stressed") Unstressed<-1
  if(newdata[3] == "Cricket") Cricket<-1
  if(newdata[3] == "Fly") Fly<-1
  if(newdata[3] == "Guppy") Guppy<-1
  if(newdata[3] == "Mite") Mite<-1
  if(newdata[3] == "Mouse") Mouse<-1
  if(newdata[1] == "B" & newdata[2] == "Stressed") interaction1<-1
  if(newdata[1] == "F" & newdata[2] == "Stressed") interaction2<-1

  predict(model.complete, newmods=c(B, F, Stressed, Cricket, Fly, Guppy, Mite, Mouse, interaction1=interaction1, interaction2=interaction2))
}
# Get the predictions for each combination of moderators
predictions.complete <- as.data.frame(expand.grid(Sex = c("M", "B", "F"),
                           Environment = c("Unstressed", "Stressed"),
                           Taxon = c("Beetle", "Cricket", "Fly", "Guppy", "Mite", "Mouse")))
predictions.complete <- cbind(predictions.complete, do.call("rbind", apply(predictions.complete, 1, get.predictions.complete))) %>%
  select(Sex, Environment, Taxon, pred, se, ci.lb, ci.ub) 
for(i in 4:7) predictions.complete[,i] <- unlist(predictions.complete[,i])
```


Thirdly, plot the model predictions for effect size (Hedges' g) for male, female and both sexes under both stressed and unstressed condition and faceted for each taxon. 

<!-- > I would like to know how to join a table with mean, and CI values to the forest plots I am generating. -->

<!-- > You can make tables with ggplot, and bind them to graphs using the grid and gridExtra packages. It's pretty hard! See ?gridExtra::tableGrob.  -->
<!-- > Honestly might be easier to do it manually with e.g. Inkscape or Illustrator.	 -->

```{r, fig.height= 7.5, fig.width=10}
pd <- position_dodgev(height = .7)
Taxon.metaanlysis <- predictions.complete %>% 
    mutate(Sex = replace(as.character(Sex), Sex == "B", "Both"),
         Sex = replace(Sex, Sex == "M", "Male"),
         Sex = replace(Sex, Sex == "F", "Female")) %>%
  ggplot(aes(x = pred, y= Environment, fill = Sex)) + 
  geom_vline(xintercept = 0, linetype = 2, colour = "grey70") + 
  geom_errorbarh(aes(xmin = predictions.complete$ci.lb, 
                     xmax = predictions.complete$ci.ub,
                     color= Sex), 
                 height = 0, position = pd, show.legend = F) +
  geom_point(position = pd, size=3, shape=21, color = "grey20") + 
  facet_grid(Taxon ~.)+
  ylab("Environment \n")+
  xlab("\nModel Prediction (Hedges g)")+
  xlim(-2, 2)+
  ggtitle('Effects of Sex and Stress on \nPopulation Fitness for Each Taxon')+
  scale_fill_brewer(palette = "Set1")+
  scale_color_brewer(palette = "Set1")+
  guides(fill = guide_legend(reverse=T))


ggsave(plot = Taxon.metaanlysis, filename = "figures/Taxon_metaanalysis_plot.eps", height = 7.5, width = 10)
Taxon.metaanlysis
```
<br></br>
**Figure S2:** The predictions from this model indicate some heterogeneity between taxon. However, the most apparent difference between taxa is that confidence bands increase for taxa with low sample size. As previously shown, the beetle and fly taxa are the most heavily sampled and in the above figure have the narrowest confidence bands. Importantly, the overall direction of effect does not change between taxon, although guppies and mice show near zero effect sizes. Here we see that under stressed environments, females from all taxa appear to have greater fitness increase than males or 'both'. 

____________

###Sexual Selection, Environment and Sex

Here we ask two key questions: Does sexual selection benefit populations in stressed environments more than unstressed environments? **AND** Do the benefits of sexual selection accrue more for female fitness components?

We run a three level model where the outcome is nested within a study (Study.ID). Other potential random effects include Species and Group.ID. However the estimate (variance from random effect) of these two other potential random effects tended towards zero and were dropped from the model. Additionally the model could be run with just Study.ID, but from our exploration of heterogeneity (below) we see that there is sufficient correlation (but not ICC = 1) between outcomes to include it as a random effect within the model. 

```{r}
#run model without taxon: same random effects as above
model.complete2 <- rma.mv(g, var.g, 
                          mods = ~ 1 + Sex * Environment, 
                          random = list(~ 1 | Study.ID, 
                                       ~ 1 | Outcome), 
                          method = "REML", 
                          data = restricted.data)
summary(model.complete2)
```


```{r, fig.height= 7.5, fig.width=10}

#Generate predictions without taxon utilising the previously described function

get.predictions.complete2 <- function(newdata){
  B<-0; F<-0; Stressed<-0; interaction1<-0; interaction2<-0; interaction3<-0
  if(newdata[1] == "B") B<-1 
  if(newdata[1] == "F") F<-1 
  if(newdata[2] == "Stressed") Unstressed<-1
  if(newdata[1] == "B" & newdata[2] == "Stressed") interaction1<-1
  if(newdata[1] == "F" & newdata[2] == "Stressed") interaction2<-1

  predict(model.complete2, newmods=c(B, F, Stressed, interaction1=interaction1, interaction2=interaction2))
}
# Get the predictions for each combination of moderators
predictions.complete2 <- as.data.frame(expand.grid(Sex = c("M", "B", "F"),
                           Environment = c("Unstressed", "Stressed")))
predictions.complete2 <- cbind(predictions.complete2, do.call("rbind", apply(predictions.complete2, 1, get.predictions.complete2))) %>%
  select(Sex, Environment, pred, se, ci.lb, ci.ub) 
for(i in 3:6) predictions.complete2[,i] <- unlist(predictions.complete2[,i])

#And plot the results
pd <- position_dodgev(height = .5)
EnvSex.metaanalysis <- predictions.complete2 %>% 
      mutate(Sex = replace(as.character(Sex), Sex == "B", "Both"),
         Sex = replace(Sex, Sex == "M", "Male"),
         Sex = replace(Sex, Sex == "F", "Female")) %>%
  ggplot(aes(x = pred, y= Environment, fill = Sex)) + 
  geom_vline(xintercept = 0, linetype = 2, colour = "grey70") + 
  geom_errorbarh(aes(xmin = predictions.complete2$ci.lb, 
                     xmax = predictions.complete2$ci.ub,
                     color = Sex), height = 0, position = pd, show.legend = F) +
  geom_point(position = pd, size=3, shape=21, color = "grey20") + 
  ylab("Environment\n")+
  xlab("\nEffect Size (Hedges g)")+
  xlim(-.75, .75)+
  ggtitle('Effects of Sex and Stress \non Population Fitness')+
  scale_fill_brewer(palette = "Set1")+
  scale_color_brewer(palette = "Set1")+
  guides(fill = guide_legend(reverse=T))

ggsave(plot = EnvSex.metaanalysis, filename = "figures/Environment_Sex_metaanalysis_plot.eps", height = 7.5, width = 10)
EnvSex.metaanalysis
```
<br></br>
**Figure S3:** Sexual selection generally increases population fitness, especially for females under stressed conditions. The benefits of sexual selection on fitness for females under stressed conditions are small-medium according to Cohen's interperetation of effect sizes. 

We see that female fitness in stressed environments is greater than the other measurements. For outcomes that were measured for both female and males we see a greater uncertainty in the estimate. It is not obviously clear why this is. The 'both' outcomes are restricted to extinction rate, offspring viability, mutant frequency and reproductive success. However, the shift from 'both' being not significant in unstressed to significant in stressed may reflect the dampening of the negative correlations (sexual antagonism).

**Comparisons of Stress vs Unstresss through anovas**

Using an anova we can test to see if a female in a stressed environment gains significantly greater fitness benefits than in an unstressed environment:

```{r}
anova(model.complete2, L=c(0, 0, 1, -1, 0, 0)) 
```

```{r}
anova(model.complete2, L=c(0, 1, 0, -1, 0, 0)) 
```


__________________________________
###Estimating Heterogeneity Using _I^2^_


Let's obtain a _I^2^_ statistic for the model above using the formulas presented here: http://www.metafor-project.org/doku.php/tips:i2_multilevel_multivariate


There are different methods to obtain estimates of _I^2^_, they should be pretty similar though. Here we obtain an overall value of _I^2^_ that is weighted based on variance where estimates of heterogeneity are sourced from sigma^2^ of the respective models. 
```{r}
#This is for the model with outcome and study as crossed random effects
W <- diag(1/restricted.data$var.g)
X <- model.matrix(model.complete2)
P <- W - W %*% X %*% solve(t(X) %*% W %*% X) %*% t(X) %*% W
100 * sum(model.complete2$sigma2) / (sum(model.complete2$sigma2) + (model.complete2$k-model.complete2$p)/sum(diag(P)))
```
This is a reasonably high _I^2^_ value but is relatively common in Ecology and Evolution (Nakagawa 2017).

To investigate the sources of heterogeneity we can obtain a breakdown of the heterogeneity for the model.
```{r}
100 * model.complete2$sigma2 / (sum(model.complete2$sigma2) + (model.complete2$k-model.complete2$p)/sum(diag(P)))
```

This indicates that 32.37 % of total heterogeneity is due to the **between study** heterogeneity and 62.17 % for **between outcome** heterogeneity between different outcomes. With the remaining 5.5 % due to sampling variance. Interestingly this might indicate that _I^2^_ would be largely reduced for a model restricted to a single outcome... Let's test this with our most common outcome...Reproductive Success

```{r}
#Reproductive Success Restriction 
restricted.dataRS <- restricted.data %>% filter(restricted.data$Outcome == "Reproductive Success")

#Run reproductive success only model 
model.completeRS <- rma.mv(g, var.g, mods = ~ 1 + Sex + Environment + Sex:Environment, random = ~ 1 | Study.ID, method = "REML", data = restricted.dataRS)


#Run estimate of heterogeneity
W2 <- diag(1/restricted.dataRS$var.g)
X2 <- model.matrix(model.completeRS)
P2 <- W2 - W2 %*% X2 %*% solve(t(X2) %*% W2 %*% X2) %*% t(X2) %*% W2
100 * sum(model.completeRS$sigma2) / (sum(model.completeRS$sigma2) + (model.completeRS$k-model.completeRS$p)/sum(diag(P2)))
```

So if we look at an individual outcomes such as reproductive success our I^2 is lower (80.97 %). Which is still high as it comes from 39 studies but lower than others. If we wanted to run models independently we could do it for those with a large enough sample size (k>10).

> Justin Says:  I am no longer sure we can use ICC as the model is not nested now, instead the random effects are crossed

Furthermore, we can obtain estimates of the intra-class correlation (ICC) within a study via: 
```{r}
round(model.complete2$sigma2[1] / sum(model.complete2$sigma2), 3)
```

This means that within a study, between different outcomes, there is a correlation of 26.2 % (low-medium). This justifies including outcome as a level, as without it we would be assuming ICC = 1. We can also gain an estimate of the total heterogeniety, as the sum of the sigma componenets: 
```{r}
round(sum(model.complete2$sigma2), 3)
```



<!-- #### Multilevel model using metafors alternative random effect structure  -->

<!-- > This inner, outer factor stuff from the metafor package is a bit strange. There is a description in ``?rma.mv()`` but still unsure how it differs from the above model. It seems that it is useful to breakdown variance-covariance matrix but unsure how that would benefit our analysis. -->

<!-- ```{r} -->
<!-- #Just to check, how about with outcome as the inner factor  -->
<!-- model.complete2.2 <- rma.mv(g, var.g, mods = ~ 1 + Sex + Environment + Sex:Environment, random = ~ factor(Outcome) | Study.ID, method = "REML", data = restricted.data) -->

<!-- summary(model.complete2.2) -->

<!-- #Now with a slightly different structure (HCS) -->

<!-- model.complete2.3 <- rma.mv(g, var.g, mods = ~ 1 + Sex + Environment + Sex:Environment, random = ~ Outcome | Study.ID, struct = "HCS", method = "REML", data = restricted.data) -->

<!-- summary(model.complete2.3) -->
<!-- ``` -->

<!-- ```{r, fig.height= 7, fig.width=10} -->
<!-- #Generate predictions without taxon -->

<!-- get.predictions.complete2 <- function(newdata){ -->
<!--   B<-0; F<-0; Stressed<-0; interaction1<-0; interaction2<-0; interaction3<-0 -->
<!--   if(newdata[1] == "B") B<-1  -->
<!--   if(newdata[1] == "F") F<-1  -->
<!--   if(newdata[2] == "Stressed") Unstressed<-1 -->
<!--   if(newdata[1] == "B" & newdata[2] == "Stressed") interaction1<-1 -->
<!--   if(newdata[1] == "F" & newdata[2] == "Stressed") interaction2<-1 -->

<!--   predict(model.complete2.2, newmods=c(B, F, Stressed, interaction1=interaction1, interaction2=interaction2)) -->
<!-- } -->
<!-- # Get the predictions for each combination of moderators -->
<!-- predictions.complete2 <- as.data.frame(expand.grid(Sex = c("M", "B", "F"), -->
<!--                            Environment = c("Unstressed", "Stressed"))) -->
<!-- predictions.complete2 <- cbind(predictions.complete2, do.call("rbind", apply(predictions.complete2, 1, get.predictions.complete2))) %>% -->
<!--   select(Sex, Environment, pred, se, ci.lb, ci.ub)  -->
<!-- for(i in 3:6) predictions.complete2[,i] <- unlist(predictions.complete2[,i]) -->

<!-- #And plot the results -->

<!-- pd <- position_dodgev(height = .3) -->
<!-- predictions.complete2 %>% ggplot(aes(x = pred, y= Environment, colour = Sex)) +  -->
<!--   geom_vline(xintercept = 0, linetype = 2, colour = "grey70") +  -->
<!--   geom_errorbarh(aes(xmin = predictions.complete2$ci.lb, xmax = predictions.complete2$ci.ub), height = 0, position = pd) + -->
<!--   geom_point(position = pd) +  -->
<!--   ylab("Environment")+ -->
<!--   xlab("Effect Size (Hedges g)")+ -->
<!--   xlim(-.75, .75)+ -->
<!--   ggtitle('Effects of Sex, Stress \non Population Fitness (OUTCOME = INNER FACTOR)') -->
<!-- ``` -->




____________________

## Multilevel Meta-Analysis on Variance

This meta-analysis on variation utilises previously described and utilised methods devoleped (Nakagawa et al. 2015; Senior et al. 2016). Our goal is to determine whether the phenotypic variance in fitness related traits is impacted by sexual selection. We would assume that if selection is occuring not only would the trait mean shift in a certain direction but the variance associated with those changes to the mean would also decrease. In this case we use an effect size statistic known as the natural log of the coefficient of variation ratio (lnCVR)


**Firstly**, we setup our calculation by creating a a restricted dataset with only unabmiguous fitness outcomes and running the functions developed by Nakagawa et al. 2015: 

```{r}
#Setup restricted data
prelim.data2 <- (prelim.data %>% filter(Outcome.Class != "Ambiguous",  Environment != "Not Stated"))

#Run function for lnCVR and associated variance of lnCVR

#for lnCVR


Calc.lnCVR<-function(CMean, CSD, CN, EMean, ESD, EN){
	
	ES<-log(ESD) - log(EMean) + 1 / (2*(EN - 1)) - (log(CSD) - log(CMean) + 1 / (2*(CN - 1)))
	
	return(ES)
	
}

#for variance of lnCVR

Calc.var.lnCVR<-function(CMean, CSD, CN, EMean, ESD, EN, Equal.E.C.Corr=T){
	
	if(Equal.E.C.Corr==T){
	
		mvcorr<-cor.test(log(c(CMean, EMean)), log(c(CSD, ESD)))$estimate
	
		S2<- CSD^2 / (CN * (CMean^2)) + 1 / (2 * (CN - 1)) - 2 * mvcorr * sqrt((CSD^2 / (CN * (CMean^2))) * (1 / (2 * (CN - 1)))) + ESD^2 / (EN * (EMean^2)) + 1 / (2 * (EN - 1)) - 2 * mvcorr * sqrt((ESD^2 / (EN * (EMean^2))) * (1 / (2 * (EN - 1))))
	
	}
	else{
		
		Cmvcorr<-cor.test(log(CMean), log(CSD))$estimate
		Emvcorr<-cor.test(log(EMean), (ESD))$estimate
	
		S2<- CSD^2 / (CN * (CMean^2)) + 1 / (2 * (CN - 1)) - 2 * Cmvcorr * sqrt((CSD^2 / (CN * (CMean^2))) * (1 / (2 * (CN - 1)))) + ESD^2 / (EN * (EMean^2)) + 1 / (2 * (EN - 1)) - 2 * Emvcorr * sqrt((ESD^2 / (EN * (EMean^2))) * (1 / (2 * (EN - 1))))		
		
		
	}
	return(S2)
	
}

```


> Justin Says: Scrap subsetting, just use exact same model as we used for Hedges' g

**Secondly**, we utilise those formulas to obtain lnCVR and var.CVR for all applicable effect sizes. Noting that not all of the dataset has means, SD and n; some were calculated from summary statistics and are not able to have lnCVR calculated:


```{r}
#Calculate lnCVr and var.lnCVr
#for lnCVR
prelim.data2$lnCVr <- Calc.lnCVR(prelim.data2$mean.low, prelim.data2$sd.low, prelim.data2$n.low, prelim.data2$mean.high, prelim.data2$sd.high, prelim.data2$n.high)

#for variance in lnCVR
prelim.data2$var.lnCVr <- Calc.var.lnCVR(prelim.data2$mean.low, prelim.data2$sd.low, prelim.data2$n.low, prelim.data2$mean.high, prelim.data2$sd.high, prelim.data2$n.high, Equal.E.C.Corr=F)
```

<!-- #Run simple models subsetted for each environment/sex (this is perhaps a clunky way so we also use predictions shown below) -->

<!-- # For stressed environment and females -->
<!-- varSF <- rma.mv(lnCVr, var.lnCVr, data = prelim.data2, mods = ~ 1, random = ~ 1 | Study.ID/Outcome, subset = (Environment == "Stressed" & Sex == "F")) -->

<!-- # For stressed environment and females -->
<!-- varSM <- rma.mv(lnCVr, var.lnCVr, data = prelim.data2, mods = ~ 1, random = ~ 1 | Study.ID/Outcome, subset = (Environment == "Stressed" & Sex == "M")) -->

<!-- # For stressed environment and females -->
<!-- varSB <- rma.mv(lnCVr, var.lnCVr, data = prelim.data2, mods = ~ 1, random = ~ 1 | Study.ID/Outcome, subset = (Environment == "Stressed" & Sex == "B")) -->

<!-- #For Benign environment and females -->
<!-- varUF<- rma.mv(lnCVr, var.lnCVr, data = prelim.data2, mods = ~1, random = ~ 1 | Study.ID/Outcome, subset = (Environment == "Unstressed" & Sex == "F")) -->

<!-- #For Benign environment and males -->
<!-- varUM<- rma.mv(lnCVr, var.lnCVr, data = prelim.data2, mods = ~1, random = ~ 1 | Study.ID/Outcome, subset = (Environment == "Unstressed" & Sex == "M")) -->

<!-- #For Benign environment and both -->
<!-- varUB <- rma.mv(lnCVr, var.lnCVr, data = prelim.data2, mods = ~1, random = ~ 1 | Study.ID/Outcome, subset = (Environment == "Unstressed" & Sex == "B")) -->

<!-- #Create dataframe of estimates and confidence intervals -->
<!-- lnCVR <- c(varSF$b, varSM$b, varSB$b, varUF$b, varUM$b, varUB$b) -->
<!-- l.ci <- c(varSF$ci.lb, varSM$ci.lb, varSB$ci.lb, varUF$ci.lb, varUM$ci.lb, varUB$ci.lb) -->
<!-- u.ci <- c(varSF$ci.ub, varSM$ci.ub, varSB$ci.ub, varUF$ci.ub, varUM$ci.ub, varUB$ci.ub) -->
<!-- Environment <- c("Stressed", "Stressed", "Stressed", "Unstressed", "Unstressed", "Unstressed") -->
<!-- Sex <- c("Female", "Male", "Both", "Female", "Male", "Both") -->
<!-- k <- c(varSF$k, varSM$k, varSB$k, varUF$k, varUM$k, varUB$k) -->

<!-- var.data <- data.frame(lnCVR, l.ci, u.ci, Environment, Sex, k) -->

<!-- #Releveling the factors to make sure it aligns with other formatted graphs -->
<!-- var.data$Environment <- var.data$Environment %>% factor %>% relevel(ref="Unstressed") -->
<!-- var.data$Sex <- var.data$Sex %>% factor %>% relevel(ref="Male") -->

<!-- #Plot subseted model estimates -->

<!-- var.data %>% ggplot(aes(x=lnCVR, y = Environment, colour = Sex))+ -->
<!--   geom_vline(xintercept = 0, linetype = 2, colour = "grey70") + -->
<!--   geom_errorbarh(aes(xmin = l.ci, xmax = u.ci), height = 0, position = pd) + -->
<!--   geom_point(position = pd) + -->
<!--   ylab("Environment")+ -->
<!--   xlab("lnCVR")+ -->
<!--   xlim(-.75, .75)+ -->
<!--   ggtitle('Meta-Analysis of Variance (Using Subsetting)') -->





**Thirdly**, although not previously done extensively, it seems that the best way to conduct this analysis is not through subsetting but through utilising model predictions as we did with Hedges' g previously, that way we retain the same methodology in model structure and test the same hypotheses. This can be done be utilising the same predict function but for lnCVR and var.lnCVR. 

Multilevel-model using lnCVR:

```{r, warning=FALSE}
#Now try with multilevel model 
variance.model <- rma.mv(lnCVr, var.lnCVr, mods = ~ 1 + Sex*Environment, 
                          random = list(~ 1 | Study.ID, 
                                       ~ 1 | Outcome), 
                         method = "REML", data = prelim.data2)
summary(variance.model)
```

Plotted predictions of lnCVR for various moderators: 

```{r, fig.height= 7.5, fig.width=10}

#Generate predictions
get.predictions.variance <- function(newdata){
  F<-0; M<-0; Stressed<-0; interaction1<-0; interaction2<-0; interaction3<-0
  if(newdata[1] == "F") F<-1 
  if(newdata[1] == "M") M<-1 
  if(newdata[2] == "Stressed") Unstressed<-1
  if(newdata[1] == "F" & newdata[2] == "Stressed") interaction1<-1
  if(newdata[1] == "M" & newdata[2] == "Stressed") interaction2<-1

  predict(variance.model, newmods=c(F, M, Stressed, interaction1=interaction1, interaction2=interaction2))
}
# Get the predictions for each combination of moderators
predictions.variance <- as.data.frame(expand.grid(Sex = c("M", "B", "F"),
                           Environment = c("Unstressed", "Stressed")))
predictions.variance <- cbind(predictions.variance, do.call("rbind", apply(predictions.variance, 1, get.predictions.variance))) %>%
  select(Sex, Environment, pred, se, ci.lb, ci.ub) 
for(i in 3:6) predictions.variance[,i] <- unlist(predictions.variance[,i])

#And plot the results

pd <- position_dodgev(height = .3)
var.plot <- predictions.variance %>% 
 mutate(Sex = replace(as.character(Sex), Sex == "B", "Both"),
        Sex = replace(Sex, Sex == "M", "Male"),
        Sex = replace(Sex, Sex == "F", "Female")) %>%
  ggplot(aes(x = pred, y= Environment, fill = Sex)) + 
  geom_vline(xintercept = 0, linetype = 2, colour = "grey70") + 
  geom_errorbarh(aes(xmin = predictions.variance$ci.lb, 
                     xmax = predictions.variance$ci.ub,
                     color = Sex), 
                 height = 0, position = pd, show.legend = F) +
  geom_point(position = pd, size=3, shape = 21, color= "grey20") + 
  ylab("Environment\n")+
  xlab("\nlnCVR")+
  xlim(-1.2, 1.2)+
  ggtitle('Meta-Analysis of Variance (Using Model Predictions)')+
  scale_fill_brewer(palette = "Set1")+
  scale_color_brewer(palette = "Set1")+
  guides(fill = guide_legend(reverse=T))

ggsave(plot = var.plot, filename = "figures/Variance_plot.eps", height = 7.5, width = 10)
var.plot
```
<br></br>
**Figure S4:** Phenotypic variation changes under sexual selection in stressful environments. For stressed females, phenotypic variation decreases (narrows). While for males in stressed environments it increases. For outcomes that measured both males and females (both) phenotypic variation did not change **or** changed for males and females in opposite directions and thus cancels out when measured together. 


____________________
##Publication Bias

###Funnel plots and Egger's Test

Checking for biases with a funnel plot. Note that the trim and fill method does not work with rma.mv objects. However we can perform Eggers test using the ``regtest()`` function. This tests for asymmetry via assessing relationships between effect size and a specified predictor. See ``?regtest`` for more information. Because the Eggers test does not work for ``rma.mv`` objects we remove the random effects and run with Sex * Environment as moderators. 
```{r}
standard.model <- rma(g, var.g, 
                      mods = ~ 1 + Sex * Environment, 
                      data=prelim.data)
regtest(standard.model)
```

We can use ggplot for creating a funnel plot. The code is pretty clunky and unlike the ``funnel.rma`` it does not use automatically plot residuals so we have to generate them independently. The outline taken from: https://sakaluk.wordpress.com/2016/02/16/7-make-it-pretty-plots-for-meta-analysis/

> Luke re-wrote this into a function, for neatness. You can replace 'dataset' and 'model' with whatever to save copy-pasting the code.

```{r, fig.height= 7.5, fig.width=10, warning=FALSE, message=FALSE}

#Using residuals for the funnel plot means that we need to generate residuals (intercept only)

forest.model <- rma.mv(g, var.g,
                       mods = ~ 1,
                       random = list(~ 1 | Study.ID,
                                       ~ 1 | Outcome),
                       method = "REML",
                       data = prelim.data)

# Obtain residuals
resstandards <- (rstandard.rma.mv(forest.model,
                                   type="response"))

# Obtain grand mean effect size    <- ADDED BY LUKE
grand.mean <- as.numeric(forest.model$b) #WHAT about weightings?

# Create new df with residuals replacing raw
df.forest.model <- prelim.data
df.forest.model$g <- resstandards$resid + grand.mean 
df.forest.model$sei <- resstandards$se

# Funnel plot for all outcome classes

make.funnel <- function(dataset, model){
  
  apatheme <- theme_bw() +  #My APA-format theme
    theme(panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.border = element_blank(),
          axis.line = element_line(),
          text = element_text(family = 'Times'),
          legend.position = 'none')
  
  estimate <- model$b
  SE <- model$se
  se.seq <- seq(0, max(sqrt(dataset$var.g)), 0.001)
  dfCI <- data.frame(ll95 = estimate - (1.96 * se.seq), 
                     ul95 = estimate + (1.96 * se.seq), 
                     ll99 = estimate - (3.29 * se.seq), 
                     ul99 = estimate + (3.29 * se.seq), 
                     se.seq = se.seq, 
                     meanll95 = estimate - (1.96 * SE), 
                     meanul95 = estimate + (1.96 * SE))
  
  ggplot(dataset, aes(x = sqrt(var.g), y = g)) +
    geom_point(size=1, shape = 21, color= "grey20") +
    xlab("Standard Error") + ylab("Effect size (Hedges' g)") +
    geom_line(aes(x = se.seq, y = ll95), linetype = 'dotted', data = dfCI) + # confidence lines
    geom_line(aes(x = se.seq, y = ul95), linetype = 'dotted', data = dfCI) +
    geom_line(aes(x = se.seq, y = ll99), linetype = 'dashed', data = dfCI) +
    geom_line(aes(x = se.seq, y = ul99), linetype = 'dashed', data = dfCI) +
    #Now plot dotted lines corresponding to the 95% CI of your meta-analytic estimate
    geom_segment(aes(x = min(se.seq), y = meanll95, xend = max(se.seq), yend = meanll95), linetype='dotted', data=dfCI, colour = "tomato") +
    geom_segment(aes(x = min(se.seq), y = meanul95, xend = max(se.seq), yend = meanul95), linetype='dotted', data=dfCI, colour = "tomato") +
    scale_x_reverse() +
    # scale_y_continuous(breaks = seq(-1.25,2,0.25)) + #Choose values that work for you based on your data
    coord_flip() +
    scale_fill_brewer(palette = "Set1")
    # theme_classic()
    # apatheme
  
}

funnel.plot <- make.funnel(df.forest.model, forest.model)

ggsave(plot = funnel.plot, filename = "figures/funnel_plot.eps", height = 7.5, width = 10)
funnel.plot

```
<br></br>
**Figure S5:** A funnel plot of 459 effect sizes shows asymmetry, indicating potential publication bias, egger's regression test for funnel plot asymmetry also suggests the plot is asymmetrical (z = 7.2671, p < .0001). The asymmetry appears to be sourced from a spread of positive effect sizes outside the funnel and of varying degrees of precision. Counter to expectations of publication bias these positive studies are not just 'low precision, large effect' results. Funnel plot asymmetry may also be due to heterogeneity, which in this study is high due to the many species and outcomes measured. 


###Journal Impact Factor

If we see a positive trend with effect size and Journal Impact Factor (JIF) it may represent publication bias whereby significant (positive) results are published more readily and in more circulated journals and non-confirmitory or negative results are not published or publiushed in lower impact journals. Our journal impact factor dataset is not evenly distributed as several publications in Nature (JIF ~ 40) are much larger than the next highest JIF (~11). 

```{r, fig.height= 7.5, fig.width=10, warning=FALSE}
JIF.plot <- prelim.data %>% ggplot(aes(x=JIF, y=g))+
  geom_jitter(color='darkgreen', alpha=.3, aes(size = (1/(var.g))/sum((1/(var.g)))*100))+
  geom_hline(yintercept=0, linetype = 'dotted')+
  geom_smooth(method='lm', color='black')+
  scale_x_continuous(breaks = c(0,10,20,30,40), limits = c(2,42.5))+
  labs(size = 'Weight (%)', y='Effect size (Hedges g)', x= 'Journal Impact Factor')

ggsave(plot = JIF.plot, filename = "figures/JIF_plot.eps", height = 7.5, width = 10)
JIF.plot
```
<br></br>
**Figure S6:** Journal impact factor does not show a noticable correlation with effect size. The positive slope shown here is due to several effect sizes published in a high impact journal. Most papers were published in discipline specific journals such as _Evolution_ and _Journal of Evolutionary Biology_. 

### Time-lag Bias

We can also look at the time-lag bias, which suggests effect size decreases over time. Again, because one publication from 1980 is well before the next publication in the late 1990s we see a very uneven distribution of data points.

```{r, fig.height= 7.5, fig.width=10, warning=FALSE}
time.plot <- prelim.data %>% 
  ggplot(aes(x=Year, y=g))+
  geom_jitter(color='darkorange', alpha=.5, aes(size = (1/(var.g))/sum((1/(var.g)))*100))+
  geom_hline(yintercept=0, linetype = 'dotted')+
  geom_smooth(method='lm', color='black')+
  labs(size = 'Weight (%)', y='Effect size (Hedges g)', x= 'Year')

ggsave(plot = time.plot, filename = "figures/time_plot.eps", height = 7.5, width = 10)
time.plot
```
<br></br>
**Figure S7:** The effect size dataset shows little to no signs of the time-lag bias as the average effect sizes from published studies remains consistent across the previous two decades. 


###Sample Size

We also collected sample sizes for each of the effect sizes calculated. Because we are dealing withj different taxa some studies are not suited to have sample sizes in the 1000's. We can simply inspect the sample size ande effect sizes through the following plot:

```{r, fig.height= 10, fig.width=5}
samplesize.plot <- prelim.data %>% ggplot(aes(x=n, y = g))+
  geom_point(fill="grey", color="grey20", shape=21)+
  scale_x_log10(breaks = c(10, 100, 1000, 10000)) + 
  #xlim(0,2100)+
  facet_grid(Taxon~., scales='free')+
  ylim(-3.5,3.5)+
  geom_hline(yintercept=0, linetype="dashed")+
  labs(y='Effect size (Hedges g)', x= 'Sample Size (n) [logscale]')

ggsave(plot = samplesize.plot, filename = "figures/samplesize_plot.eps", height = 10, width = 5)
samplesize.plot
```
<br></br>
**Figure S8:** Variation in size does not appear to have unexpected trends in any taxons, with greater variation in effect size for those studies utilising a lower sample size. 

From these plots we can see that with increased sample size the effect sizes are closer to zero. This trend is taken into account as meta-analytic models and are wighted by 1/variance. **Note** Promislow (1998) has one sample size of >10,000 in flies and is not shown here to avoid making radical changes to the scale. 

________________

##Other Moderators

### Blinding

In addition to publication bias, other forms of bias may exist within studies. We initially collected data on whether studies were blind or not. Although not many studies (n=8) used blinding there was multiple effect sizes reported in these studies, thus we can visualise whether blinding affects the effect sizes from the model. Blinding was regarded as a redundant predictor in the model (estimate = 0.0287, p = 0.8974) and was dropped. 

```{r, fig.height= 7.5, fig.width=10}
blind.plot <- df.forest.model %>% ggplot(aes(x=Blinding, y=g))+
  geom_boxplot(outlier.shape = NA)+
  geom_jitter(aes(fill=Blinding, size = (1/(var.g))/sum((1/(var.g)))*100), shape=21, color='grey20')+
  geom_hline(yintercept=0, linetype = 'dotted') + 
  scale_fill_brewer(palette = "Set2")+
  labs(y='Effect size (Hedges g)', x= 'Blinding', size = 'Weight (%)')+
  guides(fill=FALSE)

ggsave(plot = blind.plot, filename = "figures/blind_plot.eps", height = 7.5, width = 10)
blind.plot
```
<br></br>
**Figure S9:** Blinding does not appear to alter the magnitude or direction of effect sizes for the studies used in this meta-analysis. However, this should not be viewed as evidence against the validity of blinding as a research method. 


### Generations

We recorded the number of generations of experimental exolution each study used. The number of generations proved a negligible predictor in the meta-analytic models (estimate = 0.0019, p = 0.2341). The effect sizes are plotted against the generation at which the effect size was extracted. 

```{r, fig.height= 7.5, fig.width=10, warning=FALSE}
generations.plot <- df.forest.model %>% ggplot(aes(x=Generations, y=g))+
  geom_point(shape=21, color = "grey20", size=2, aes(fill=Taxon))+
  ylim(-3.5,3.5)+
  geom_hline(yintercept=0, linetype="dashed") + 
  scale_fill_brewer(palette = "Set3")+
  geom_smooth(method = 'lm', color='black')+
  labs(y='Effect size (Hedges g)', x= 'Generations', size= 'Weight (%)')

ggsave(plot = generations.plot, filename = "figures/generations_plot.eps", height = 7.5, width = 10)
generations.plot
```
<br></br>
**Figure S10:** The number of generations an experimental evolution procedure is run for does not appear to affect the magnitude or direction of the effect size from the fitness related outcome measured at that point. 

________________

##R Session Information

This section shows the operating system and R packages attached during the production of this document

```{r}
sessionInfo() %>% pander
```



<!-- Some JavaScript to control the buttons to show/hide the big tables -->
<script>
$( "input.hideshow" ).each( function ( index, button ) {
  button.value = 'Hide Output';
  $( button ).click( function () {
    var target = this.nextSibling ? this : this.parentNode;
     target = target.nextSibling.nextSibling.nextSibling.nextSibling.nextSibling;
    if ( target.style.display == 'block' || target.style.display == '' ) {
      target.style.display = 'none';
      this.value = 'Show Output';
    } else {
      target.style.display = 'block';
      this.value = 'Hide Output';
    }
  } );
} );
</script>
